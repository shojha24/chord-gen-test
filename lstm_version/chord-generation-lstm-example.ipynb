{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10480441,"sourceType":"datasetVersion","datasetId":6489604},{"sourceId":10768712,"sourceType":"datasetVersion","datasetId":6680282},{"sourceId":10857170,"sourceType":"datasetVersion","datasetId":6743943}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport re\nimport pandas as pd\n!pip install liac-arff\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-10T22:25:38.497981Z","iopub.execute_input":"2025-04-10T22:25:38.498335Z","iopub.status.idle":"2025-04-10T22:25:42.793070Z","shell.execute_reply.started":"2025-04-10T22:25:38.498309Z","shell.execute_reply":"2025-04-10T22:25:42.791452Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: liac-arff in /usr/local/lib/python3.10/dist-packages (2.5.0)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Preprocessing steps:\n# 1: condense onset files to just onset times and onset notes\n\"\"\"\nimport re\nimport pandas as pd\nimport arff\n\n# Directory path to your annotations folder\nannotations_dir = \"/kaggle/input/aam-annotations/AAM-annotations/\"\nnum = 0\n\n# Iterate through all files in the directory\nfor filename in os.listdir(annotations_dir):\n    if \"onsets\" in filename and filename.endswith(\".arff\"):  # Ensure it's an ARFF file with 'onsets' in its name\n        num += 1\n        file_path = os.path.join(annotations_dir, filename)\n        \n        # Read the ARFF file\n        def read_arff(file_path):\n            with open(file_path, 'r') as f:\n                arff_data = arff.load(f)\n            return pd.DataFrame(arff_data['data'], columns=[attr[0] for attr in arff_data['attributes']])\n        \n        # Use this function instead of manual parsing\n        df = read_arff(file_path)\n\n        # Convert numeric columns where possible\n        for col in df.columns:\n            try:\n                df[col] = pd.to_numeric(df[col])  # Convert if possible\n            except ValueError:\n                pass  # Keep as string if conversion fails\n\n        all_onsets = []\n\n        # Vectorized operation to collect all onset events\n        df.drop(columns=[\"Onset events of Drums\"], inplace=True)\n        onset_columns = df.columns[df.apply(lambda col: col.astype(str).str.contains(r\"\\[\", regex=True)).any()]\n        df[\"Onset events\"] = df[onset_columns].apply(lambda row: [int(x) for x in re.findall(r'\\d+', ''.join(row.astype(str)))], axis=1)\n        df.drop(onset_columns, axis=1, inplace=True)\n\n        # Save the processed DataFrame to a new CSV file\n        output_file = re.search(\"(\\d+)\", filename).group(0) + \"_onset_condensed.csv\"\n        df.to_csv(output_file, index=False)\n\n        if num % 100 == 0:\n            print(f\"Processed {filename} and saved to {output_file}\")\"\"\"","metadata":{"execution":{"iopub.status.busy":"2025-04-10T22:25:42.795451Z","iopub.execute_input":"2025-04-10T22:25:42.795896Z","iopub.status.idle":"2025-04-10T22:25:42.803460Z","shell.execute_reply.started":"2025-04-10T22:25:42.795861Z","shell.execute_reply":"2025-04-10T22:25:42.802436Z"},"trusted":true},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'\\nimport re\\nimport pandas as pd\\nimport arff\\n\\n# Directory path to your annotations folder\\nannotations_dir = \"/kaggle/input/aam-annotations/AAM-annotations/\"\\nnum = 0\\n\\n# Iterate through all files in the directory\\nfor filename in os.listdir(annotations_dir):\\n    if \"onsets\" in filename and filename.endswith(\".arff\"):  # Ensure it\\'s an ARFF file with \\'onsets\\' in its name\\n        num += 1\\n        file_path = os.path.join(annotations_dir, filename)\\n        \\n        # Read the ARFF file\\n        def read_arff(file_path):\\n            with open(file_path, \\'r\\') as f:\\n                arff_data = arff.load(f)\\n            return pd.DataFrame(arff_data[\\'data\\'], columns=[attr[0] for attr in arff_data[\\'attributes\\']])\\n        \\n        # Use this function instead of manual parsing\\n        df = read_arff(file_path)\\n\\n        # Convert numeric columns where possible\\n        for col in df.columns:\\n            try:\\n                df[col] = pd.to_numeric(df[col])  # Convert if possible\\n            except ValueError:\\n                pass  # Keep as string if conversion fails\\n\\n        all_onsets = []\\n\\n        # Vectorized operation to collect all onset events\\n        df.drop(columns=[\"Onset events of Drums\"], inplace=True)\\n        onset_columns = df.columns[df.apply(lambda col: col.astype(str).str.contains(r\"\\\\[\", regex=True)).any()]\\n        df[\"Onset events\"] = df[onset_columns].apply(lambda row: [int(x) for x in re.findall(r\\'\\\\d+\\', \\'\\'.join(row.astype(str)))], axis=1)\\n        df.drop(onset_columns, axis=1, inplace=True)\\n\\n        # Save the processed DataFrame to a new CSV file\\n        output_file = re.search(\"(\\\\d+)\", filename).group(0) + \"_onset_condensed.csv\"\\n        df.to_csv(output_file, index=False)\\n\\n        if num % 100 == 0:\\n            print(f\"Processed {filename} and saved to {output_file}\")'"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"# 2: encode chord names and replace said chord names with encodings in beatinfo files\n\nchord_encodings = {0: 'A#maj', 1: 'A#min', 2: 'Amaj', 3: 'Amin', 4: 'Bmaj', 5: 'Bmin', 6: 'C#maj', 7: 'C#min', \n                   8: 'Cmaj', 9: 'Cmin', 10: 'D#maj', 11: 'D#min', 12: 'Dmaj', 13: 'Dmin', 14: 'Emaj', 15: 'Emin', \n                   16: 'F#maj', 17: 'F#min', 18: 'Fmaj', 19: 'Fmin', 20: 'G#maj', 21: 'G#min', 22: 'Gmaj', \n                   23: 'Gmin', 24: 'N.C.'}\n\ninverted_encodings = {'A#maj': 0, 'A#min': 1, 'Amaj': 2, 'Amin': 3, 'Bmaj': 4, 'Bmin': 5, 'C#maj': 6, 'C#min': 7, \n                   'Cmaj': 8, 'Cmin': 9, 'D#maj': 10, 'D#min': 11, 'Dmaj': 12, 'Dmin': 13, 'Emaj': 14, 'Emin': 15, \n                   'F#maj': 16, 'F#min': 17, 'Fmaj': 18, 'Fmin': 19, 'G#maj': 20, 'G#min': 21, 'Gmaj': 22, \n                   'Gmin': 23, 'N.C.': 24}\n\n\"\"\"\n# Directory path to your annotations folder\nheaders = ['Start time in seconds', 'Bar count', 'Quarter count', 'Chord name']\n\n# Iterate through all files in the directory\nfor filename in os.listdir(annotations_dir):\n    if \"beatinfo\" in filename and filename.endswith(\".arff\"):  # Ensure it's an ARFF file with 'beatinfo' in its name\n        file_path = os.path.join(annotations_dir, filename)\n        df = pd.read_csv(file_path, comment='@', header=None)\n        df.columns = headers\n\n        for i in range(df.index.size):\n            df.iat[i, 3] = df.iat[i, 3].replace(\"'\", \"\")\n            if df.iat[i, 3] == \"BASS_NOTE_EXCEPTION\":\n                df.iat[i, 3] = \"N.C.\"\n            df.iat[i, 3] = inverted_encodings[df.iat[i, 3]]\n    \n        df.to_csv(filename.replace('arff', 'csv'), index=False)\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T22:25:42.805790Z","iopub.execute_input":"2025-04-10T22:25:42.806156Z","iopub.status.idle":"2025-04-10T22:25:42.833590Z","shell.execute_reply.started":"2025-04-10T22:25:42.806130Z","shell.execute_reply":"2025-04-10T22:25:42.832436Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'\\n# Directory path to your annotations folder\\nheaders = [\\'Start time in seconds\\', \\'Bar count\\', \\'Quarter count\\', \\'Chord name\\']\\n\\n# Iterate through all files in the directory\\nfor filename in os.listdir(annotations_dir):\\n    if \"beatinfo\" in filename and filename.endswith(\".arff\"):  # Ensure it\\'s an ARFF file with \\'beatinfo\\' in its name\\n        file_path = os.path.join(annotations_dir, filename)\\n        df = pd.read_csv(file_path, comment=\\'@\\', header=None)\\n        df.columns = headers\\n\\n        for i in range(df.index.size):\\n            df.iat[i, 3] = df.iat[i, 3].replace(\"\\'\", \"\")\\n            if df.iat[i, 3] == \"BASS_NOTE_EXCEPTION\":\\n                df.iat[i, 3] = \"N.C.\"\\n            df.iat[i, 3] = inverted_encodings[df.iat[i, 3]]\\n    \\n        df.to_csv(filename.replace(\\'arff\\', \\'csv\\'), index=False)'"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# visualize the files\n\n###working_dir = \"/kaggle/working/\"\nworking_dir = \"/kaggle/input/aam-paired-chord-onset-dataset/\"\nonsets = pd.read_csv(working_dir + \"0001_onset_condensed.csv\")\nprint(onsets.head())\nbeatinfo = pd.read_csv(working_dir + \"0001_beatinfo.csv\")\nprint(beatinfo.head())\n\ndef align_onsets_with_chords(onsets, beatinfo):\n    aligned_data = []\n    for _, onset_row in onsets.iterrows():\n        onset_time = onset_row['Onset time in seconds']\n        # Find the chord corresponding to this onset time\n        chord_row = beatinfo[beatinfo['Start time in seconds'] <= onset_time].iloc[-1]\n        onset_list = eval(onset_row['Onset events'])\n        if chord_row['Chord name'] != 24 and len(onset_list) > 0:\n            aligned_data.append((onset_list, chord_row['Chord name']))\n    return aligned_data","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-10T23:17:18.141Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# create aligned data for every onset and beatinfo file\n\nall_data = []\ni = 0\n\nwhile i < 100:\n    i += 1\n    onset_path = os.path.join(working_dir, f\"{i :04d}_onset_condensed.csv\")\n    beatinfo_path = os.path.join(working_dir, f\"{i :04d}_beatinfo.csv\")\n    onsets = pd.read_csv(onset_path)\n    beatinfo = pd.read_csv(beatinfo_path)\n    all_data.append(align_onsets_with_chords(onsets, beatinfo))\n\nprint(all_data[0:1])\n#print(all_data[0:20])","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-10T23:17:18.142Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Implement an LSTM\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Embedding, LSTM, Dense, TimeDistributed, BatchNormalization\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\n\ndef create_chord_classification_model(vocab_size, embedding_dim, lstm_units, num_classes, max_sequence_length):\n    # Input for note sequences\n    note_input = Input(shape=(max_sequence_length,))\n    \n    # Embedding layer for note sequences\n    note_embedding = Embedding(vocab_size, embedding_dim)(note_input)\n    \n    # LSTM layers\n    lstm_output = LSTM(lstm_units, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(note_embedding) # with more lstm layers, return sequences = true\n    lstm_output = BatchNormalization()(lstm_output)\n    lstm_output = LSTM(lstm_units, return_sequences=False, dropout=0.2, recurrent_dropout=0.2)(lstm_output)\n    \n    # Output layer\n    output = Dense(num_classes, activation='softmax', kernel_regularizer=l2(0.01))(lstm_output)\n    \n    model = Model(inputs=note_input, outputs=output)\n    return model\n\n# Hyperparameters\nvocab_size = 128  # Assuming MIDI note range\nembedding_dim = 64\nlstm_units = 64\nnum_classes = 24  # Number of chord classes\nmax_sequence_length = 16  # Adjust based on your data\n\n# Create the model\nmodel = create_chord_classification_model(vocab_size, embedding_dim, lstm_units, num_classes, max_sequence_length)\n\n# Compile the model\noptimizer = Adam(learning_rate=0.0001)\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Split at the song level (here I can decide how many of the songs I want to use)\ntrain_songs, test_songs = train_test_split(all_data[0:100], test_size=0.2, random_state=42)\n\n# Flatten sequences within each split\ntrain_data = [pair for song in train_songs for pair in song]  # Keep full song sequences together\ntest_data = [pair for song in test_songs for pair in song]\n\nprint(f\"Total training sequences: {len(train_data)}\")\nprint(f\"Total testing sequences: {len(test_data)}\")\n\n# Function to prepare data\ndef prepare_data(data, max_sequence_length):\n    X, y = [], []\n    for notes, chord in data:\n        padded_notes = tf.keras.preprocessing.sequence.pad_sequences([notes], maxlen=max_sequence_length, padding='post', truncating='post')[0]\n        X.append(padded_notes)\n        y.append(chord)\n    return np.array(X), np.array(y)\n\n# Prepare train and test data\nX_train, y_train = prepare_data(train_data, max_sequence_length)\nX_test, y_test = prepare_data(test_data, max_sequence_length)\n\n# Convert y to one-hot encoding\ny_train_onehot = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\ny_test_onehot = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)\n\n# Train the model\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\nmodel_save = ModelCheckpoint('checkpoint.model.keras', save_best_only=True, monitor='val_accuracy', mode='max')\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n\nhistory = model.fit(X_train, y_train_onehot, validation_data=(X_test, y_test_onehot), epochs=100, batch_size=32, callbacks=[early_stopping])\n\nmodel.save('BestChordPredictor.keras')\n\n# Function for inference\ndef predict_chord(model, note_sequence):\n    padded_sequence = tf.keras.preprocessing.sequence.pad_sequences([note_sequence], maxlen=max_sequence_length, padding='post', truncating='post')\n    predictions = model.predict(padded_sequence)\n    return np.argmax(predictions[0])  # Return the prediction\n\n# Example usage\nsample_sequence = [60, 64, 67, 72]  # C major chor\npredicted_chord = predict_chord(model, sample_sequence)\nprint(f\"Predicted chord num: {predicted_chord}\")\nprint(f\"Predicted chord: {chord_encodings[predicted_chord]}\")\n\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-10T23:17:18.142Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chords = {\n    \"C Major\": [60, 64, 67, 72],\n    \"C Minor\": [60, 63, 67, 72],\n    \n    \"C# Major / Db Major\": [61, 65, 68, 73],\n    \"C# Minor / Db Minor\": [61, 64, 68, 73],\n    \n    \"D Major\": [62, 66, 69, 74],\n    \"D Minor\": [62, 65, 69, 74],\n    \n    \"D# Major / Eb Major\": [63, 67, 70, 75],\n    \"D# Minor / Eb Minor\": [63, 66, 70, 75],\n    \n    \"E Major\": [64, 68, 71, 76],\n    \"E Minor\": [64, 67, 71, 76],\n    \n    \"F Major\": [65, 69, 72, 77],\n    \"F Minor\": [65, 68, 72, 77],\n    \n    \"F# Major / Gb Major\": [66, 70, 73, 78],\n    \"F# Minor / Gb Minor\": [66, 69, 73, 78],\n    \n    \"G Major\": [67, 71, 74, 79],\n    \"G Minor\": [67, 70, 74, 79],\n    \n    \"G# Major / Ab Major\": [68, 72, 75, 80],\n    \"G# Minor / Ab Minor\": [68, 71, 75, 80],\n    \n    \"A Major\": [69, 73, 76, 81],\n    \"A Minor\": [69, 72, 76, 81],\n    \n    \"A# Major / Bb Major\": [70, 74, 77, 82],\n    \"A# Minor / Bb Minor\": [70, 73, 77, 82],\n    \n    \"B Major\": [71, 75, 78, 83],\n    \"B Minor\": [71, 74, 78, 83]\n}\n\nfor chord in chords.values():\n    pred_chord = predict_chord(model, chord)\n    print(chord_encodings[pred_chord])","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-10T23:17:18.142Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\n#Predict\nY_prediction = model.predict(X_test)\nY_prediction = np.argmax (Y_prediction, axis = 1)\nY_test=np.argmax(y_test_onehot, axis=1)\n\n#Create confusion matrix and normalizes it over predicted (columns)\nresult = confusion_matrix(Y_test, Y_prediction , normalize='pred')\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-10T23:17:18.142Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sn\nimport matplotlib.pyplot as plt\n\ndf_cm = pd.DataFrame(result, range(24), range(24))\nplt.figure(figsize=(14,10))\nsn.set(font_scale=1.7) # for label size\nsn.heatmap(df_cm, annot=True, annot_kws={\"size\": 6}) # font size\n\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-10T23:17:18.142Z"}},"outputs":[],"execution_count":null}]}