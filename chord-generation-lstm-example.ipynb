{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10480441,"sourceType":"datasetVersion","datasetId":6489604},{"sourceId":10768712,"sourceType":"datasetVersion","datasetId":6680282}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sharabhojha/chord-generation-lstm-example?scriptVersionId=224195738\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n!pip install liac-arff\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T05:02:52.218163Z","iopub.execute_input":"2025-02-24T05:02:52.218563Z","iopub.status.idle":"2025-02-24T05:03:00.790143Z","shell.execute_reply.started":"2025-02-24T05:02:52.218528Z","shell.execute_reply":"2025-02-24T05:03:00.788725Z"}},"outputs":[{"name":"stdout","text":"Collecting liac-arff\n  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nBuilding wheels for collected packages: liac-arff\n  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11716 sha256=a0780944bac2c00781af97033b813f8325bd6987a7f7f7e0582d6488df595348\n  Stored in directory: /root/.cache/pip/wheels/5d/2a/9c/3895d9617f8f49a0883ba686326d598e78a1c2f54fe3cae86d\nSuccessfully built liac-arff\nInstalling collected packages: liac-arff\nSuccessfully installed liac-arff-2.5.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Preprocessing steps:\n# 1: condense onset files to just onset times and onset notes\n\nimport os\nimport re\nimport pandas as pd\nimport arff\n\n# Directory path to your annotations folder\nannotations_dir = \"/kaggle/input/aam-annotations/AAM-annotations/\"\nnum = 0\n\n# Iterate through all files in the directory\nfor filename in os.listdir(annotations_dir):\n    if \"onsets\" in filename and filename.endswith(\".arff\"):  # Ensure it's an ARFF file with 'onsets' in its name\n        num += 1\n        file_path = os.path.join(annotations_dir, filename)\n        \n        # Read the ARFF file\n        def read_arff(file_path):\n            with open(file_path, 'r') as f:\n                arff_data = arff.load(f)\n            return pd.DataFrame(arff_data['data'], columns=[attr[0] for attr in arff_data['attributes']])\n        \n        # Use this function instead of manual parsing\n        df = read_arff(file_path)\n\n        # Convert numeric columns where possible\n        for col in df.columns:\n            try:\n                df[col] = pd.to_numeric(df[col])  # Convert if possible\n            except ValueError:\n                pass  # Keep as string if conversion fails\n\n        all_onsets = []\n\n        # Vectorized operation to collect all onset events\n        df.drop(columns=[\"Onset events of Drums\"], inplace=True)\n        onset_columns = df.columns[df.apply(lambda col: col.astype(str).str.contains(r\"\\[\", regex=True)).any()]\n        df[\"Onset events\"] = df[onset_columns].apply(lambda row: [int(x) for x in re.findall(r'\\d+', ''.join(row.astype(str)))], axis=1)\n        df.drop(onset_columns, axis=1, inplace=True)\n\n        # Save the processed DataFrame to a new CSV file\n        output_file = re.search(\"(\\d+)\", filename).group(0) + \"_onset_condensed.csv\"\n        df.to_csv(output_file, index=False)\n\n        if num % 100 == 0:\n            print(f\"Processed {filename} and saved to {output_file}\")","metadata":{"execution":{"iopub.status.busy":"2025-02-24T05:03:08.943203Z","iopub.execute_input":"2025-02-24T05:03:08.944081Z","iopub.status.idle":"2025-02-24T05:08:26.266938Z","shell.execute_reply.started":"2025-02-24T05:03:08.94404Z","shell.execute_reply":"2025-02-24T05:08:26.265921Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Processed 0521_onsets.arff and saved to 0521_onset_condensed.csv\nProcessed 2699_onsets.arff and saved to 2699_onset_condensed.csv\nProcessed 2634_onsets.arff and saved to 2634_onset_condensed.csv\nProcessed 0544_onsets.arff and saved to 0544_onset_condensed.csv\nProcessed 1658_onsets.arff and saved to 1658_onset_condensed.csv\nProcessed 1624_onsets.arff and saved to 1624_onset_condensed.csv\nProcessed 1192_onsets.arff and saved to 1192_onset_condensed.csv\nProcessed 0001_onsets.arff and saved to 0001_onset_condensed.csv\nProcessed 0382_onsets.arff and saved to 0382_onset_condensed.csv\nProcessed 1000_onsets.arff and saved to 1000_onset_condensed.csv\nProcessed 0541_onsets.arff and saved to 0541_onset_condensed.csv\nProcessed 1630_onsets.arff and saved to 1630_onset_condensed.csv\nProcessed 0696_onsets.arff and saved to 0696_onset_condensed.csv\nProcessed 0121_onsets.arff and saved to 0121_onset_condensed.csv\nProcessed 0097_onsets.arff and saved to 0097_onset_condensed.csv\nProcessed 0220_onsets.arff and saved to 0220_onset_condensed.csv\nProcessed 1161_onsets.arff and saved to 1161_onset_condensed.csv\nProcessed 2537_onsets.arff and saved to 2537_onset_condensed.csv\nProcessed 1108_onsets.arff and saved to 1108_onset_condensed.csv\nProcessed 0558_onsets.arff and saved to 0558_onset_condensed.csv\nProcessed 0564_onsets.arff and saved to 0564_onset_condensed.csv\nProcessed 2885_onsets.arff and saved to 2885_onset_condensed.csv\nProcessed 0646_onsets.arff and saved to 0646_onset_condensed.csv\nProcessed 2182_onsets.arff and saved to 2182_onset_condensed.csv\nProcessed 1541_onsets.arff and saved to 1541_onset_condensed.csv\nProcessed 1601_onsets.arff and saved to 1601_onset_condensed.csv\nProcessed 0352_onsets.arff and saved to 0352_onset_condensed.csv\nProcessed 1210_onsets.arff and saved to 1210_onset_condensed.csv\nProcessed 1189_onsets.arff and saved to 1189_onset_condensed.csv\nProcessed 2995_onsets.arff and saved to 2995_onset_condensed.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# 2: encode chord names and replace said chord names with encodings in beatinfo files\n\n# Directory path to your annotations folder\nheaders = ['Start time in seconds', 'Bar count', 'Quarter count', 'Chord name']\n\nchord_encodings = {0: 'A#maj', 1: 'A#min', 2: 'Amaj', 3: 'Amin', 4: 'Bmaj', 5: 'Bmin', 6: 'C#maj', 7: 'C#min', \n                   8: 'Cmaj', 9: 'Cmin', 10: 'D#maj', 11: 'D#min', 12: 'Dmaj', 13: 'Dmin', 14: 'Emaj', 15: 'Emin', \n                   16: 'F#maj', 17: 'F#min', 18: 'Fmaj', 19: 'Fmin', 20: 'G#maj', 21: 'G#min', 22: 'Gmaj', \n                   23: 'Gmin', 24: 'N.C.'}\n\ninverted_encodings = {'A#maj': 0, 'A#min': 1, 'Amaj': 2, 'Amin': 3, 'Bmaj': 4, 'Bmin': 5, 'C#maj': 6, 'C#min': 7, \n                   'Cmaj': 8, 'Cmin': 9, 'D#maj': 10, 'D#min': 11, 'Dmaj': 12, 'Dmin': 13, 'Emaj': 14, 'Emin': 15, \n                   'F#maj': 16, 'F#min': 17, 'Fmaj': 18, 'Fmin': 19, 'G#maj': 20, 'G#min': 21, 'Gmaj': 22, \n                   'Gmin': 23, 'N.C.': 24}\n\n# Iterate through all files in the directory\nfor filename in os.listdir(annotations_dir):\n    if \"beatinfo\" in filename and filename.endswith(\".arff\"):  # Ensure it's an ARFF file with 'beatinfo' in its name\n        file_path = os.path.join(annotations_dir, filename)\n        df = pd.read_csv(file_path, comment='@', header=None)\n        df.columns = headers\n\n        for i in range(df.index.size):\n            df.iat[i, 3] = df.iat[i, 3].replace(\"'\", \"\")\n            if df.iat[i, 3] == \"BASS_NOTE_EXCEPTION\":\n                df.iat[i, 3] = \"N.C.\"\n            df.iat[i, 3] = inverted_encodings[df.iat[i, 3]]\n    \n        df.to_csv(filename.replace('arff', 'csv'), index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T05:09:10.827942Z","iopub.execute_input":"2025-02-24T05:09:10.828359Z","iopub.status.idle":"2025-02-24T05:10:39.634847Z","shell.execute_reply.started":"2025-02-24T05:09:10.828262Z","shell.execute_reply":"2025-02-24T05:10:39.633614Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# visualize the files\nworking_dir = \"/kaggle/working/\"\nonsets = pd.read_csv(working_dir + \"0001_onset_condensed.csv\")\nprint(onsets.head())\nbeatinfo = pd.read_csv(working_dir + \"0001_beatinfo.csv\")\nprint(beatinfo.head())\n\ndef align_onsets_with_chords(onsets, beatinfo):\n    aligned_data = []\n    for _, onset_row in onsets.iterrows():\n        onset_time = onset_row['Onset time in seconds']\n        # Find the chord corresponding to this onset time\n        chord_row = beatinfo[beatinfo['Start time in seconds'] <= onset_time].iloc[-1]\n        onset_list = eval(onset_row['Onset events'])\n        if chord_row['Chord name'] != 'N.C' and len(onset_list) > 0:\n            aligned_data.append((onset_list, chord_row['Chord name']))\n    return aligned_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T05:11:35.434356Z","iopub.execute_input":"2025-02-24T05:11:35.434718Z","iopub.status.idle":"2025-02-24T05:11:35.45453Z","shell.execute_reply.started":"2025-02-24T05:11:35.434691Z","shell.execute_reply":"2025-02-24T05:11:35.453406Z"}},"outputs":[{"name":"stdout","text":"   Onset time in seconds  Onset events\n0               0.000000  [41, 60, 65]\n1               0.326086      [41, 60]\n2               0.652173  [41, 65, 65]\n3               0.978259  [41, 65, 69]\n4               1.304346  [41, 65, 65]\n   Start time in seconds  Bar count  Quarter count  Chord name\n0               0.000000          1              1          18\n1               0.652174          1              2          18\n2               1.304348          1              3          18\n3               1.956522          1              4          18\n4               2.608696          2              1           0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# create aligned data for every onset and beatinfo file\n\nall_data = []\ni = 0\n\nwhile i < 3000:\n    i += 1\n    onset_path = os.path.join(working_dir, f\"{i :04d}_onset_condensed.csv\")\n    beatinfo_path = os.path.join(working_dir, f\"{i :04d}_beatinfo.csv\")\n    onsets = pd.read_csv(onset_path)\n    beatinfo = pd.read_csv(beatinfo_path)\n    all_data.append(align_onsets_with_chords(onsets, beatinfo))\n\nprint(len(all_data))\n#print(all_data[0:20])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T05:11:39.92387Z","iopub.execute_input":"2025-02-24T05:11:39.92422Z","iopub.status.idle":"2025-02-24T05:26:02.779536Z","shell.execute_reply.started":"2025-02-24T05:11:39.924189Z","shell.execute_reply":"2025-02-24T05:26:02.778455Z"}},"outputs":[{"name":"stdout","text":"3000\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Embedding, LSTM, Dense, TimeDistributed, BatchNormalization\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\n\ndef create_chord_classification_model(vocab_size, embedding_dim, lstm_units, num_classes, max_sequence_length):\n    # Input for note sequences\n    note_input = Input(shape=(max_sequence_length,))\n    \n    # Embedding layer for note sequences\n    note_embedding = Embedding(vocab_size, embedding_dim)(note_input)\n    \n    # LSTM layers\n    lstm_output = LSTM(lstm_units, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(note_embedding) # with more lstm layers, return sequences = true\n    lstm_output = BatchNormalization()(lstm_output)\n    lstm_output = LSTM(lstm_units, return_sequences=False, dropout=0.2, recurrent_dropout=0.2)(lstm_output)\n    \n    # Output layer\n    output = Dense(num_classes, activation='softmax', kernel_regularizer=l2(0.01))(lstm_output)\n    \n    model = Model(inputs=note_input, outputs=output)\n    return model\n\n# Hyperparameters\nvocab_size = 128  # Assuming MIDI note range\nembedding_dim = 64\nlstm_units = 64\nnum_classes = 25  # Number of chord classes\nmax_sequence_length = 16  # Adjust based on your data\n\n# Create the model\nmodel = create_chord_classification_model(vocab_size, embedding_dim, lstm_units, num_classes, max_sequence_length)\n\n# Compile the model\noptimizer = Adam(learning_rate=0.0001)\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Split at the song level (here I can decide how many of the songs I want to use)\ntrain_songs, test_songs = train_test_split(all_data[0:400], test_size=0.2, random_state=42)\n\n# Flatten sequences within each split\ntrain_data = [pair for song in train_songs for pair in song]  # Keep full song sequences together\ntest_data = [pair for song in test_songs for pair in song]\n\nprint(f\"Total training sequences: {len(train_data)}\")\nprint(f\"Total testing sequences: {len(test_data)}\")\n\n# Function to prepare data\ndef prepare_data(data, max_sequence_length):\n    X, y = [], []\n    for notes, chord in data:\n        padded_notes = tf.keras.preprocessing.sequence.pad_sequences([notes], maxlen=max_sequence_length, padding='post', truncating='post')[0]\n        X.append(padded_notes)\n        y.append(chord)\n    return np.array(X), np.array(y)\n\n# Prepare train and test data\nX_train, y_train = prepare_data(train_data, max_sequence_length)\nX_test, y_test = prepare_data(test_data, max_sequence_length)\n\n# Convert y to one-hot encoding\ny_train_onehot = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\ny_test_onehot = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)\n\n# Train the model\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\nhistory = model.fit(X_train, y_train_onehot, validation_data=(X_test, y_test_onehot), epochs=100, batch_size=32, callbacks=[early_stopping])\n\nmodel.save('BestChordPredictor.keras')\n\n# Function for inference\ndef predict_chord(model, note_sequence):\n    padded_sequence = tf.keras.preprocessing.sequence.pad_sequences([note_sequence], maxlen=max_sequence_length, padding='post', truncating='post')\n    predictions = model.predict(padded_sequence)\n    return np.argmax(predictions[0])  # Return the prediction\n\n# Example usage\nsample_sequence = [60, 64, 67, 72]  # C major chor\npredicted_chord = predict_chord(model, sample_sequence)\nprint(f\"Predicted chord num: {predicted_chord}\")\nprint(f\"Predicted chord: {chord_encodings[predicted_chord]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T06:49:14.383558Z","iopub.execute_input":"2025-02-24T06:49:14.383971Z","iopub.status.idle":"2025-02-24T07:54:10.760607Z","shell.execute_reply.started":"2025-02-24T06:49:14.38394Z","shell.execute_reply":"2025-02-24T07:54:10.759471Z"}},"outputs":[{"name":"stdout","text":"Total training sequences: 180038\nTotal testing sequences: 43994\nEpoch 1/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 19ms/step - accuracy: 0.4746 - loss: 2.2543 - val_accuracy: 0.8128 - val_loss: 1.0939\nEpoch 2/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 19ms/step - accuracy: 0.7872 - loss: 1.1776 - val_accuracy: 0.8144 - val_loss: 1.0181\nEpoch 3/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 20ms/step - accuracy: 0.8030 - loss: 1.0723 - val_accuracy: 0.8163 - val_loss: 0.9849\nEpoch 4/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 19ms/step - accuracy: 0.8100 - loss: 1.0233 - val_accuracy: 0.8188 - val_loss: 0.9672\nEpoch 5/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 19ms/step - accuracy: 0.8135 - loss: 1.0018 - val_accuracy: 0.8179 - val_loss: 0.9554\nEpoch 6/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 19ms/step - accuracy: 0.8149 - loss: 0.9869 - val_accuracy: 0.8168 - val_loss: 0.9535\nEpoch 7/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 19ms/step - accuracy: 0.8167 - loss: 0.9777 - val_accuracy: 0.8187 - val_loss: 0.9459\nEpoch 8/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 19ms/step - accuracy: 0.8177 - loss: 0.9684 - val_accuracy: 0.8196 - val_loss: 0.9425\nEpoch 9/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 19ms/step - accuracy: 0.8197 - loss: 0.9600 - val_accuracy: 0.8193 - val_loss: 0.9367\nEpoch 10/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 19ms/step - accuracy: 0.8212 - loss: 0.9528 - val_accuracy: 0.8190 - val_loss: 0.9367\nEpoch 11/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 19ms/step - accuracy: 0.8209 - loss: 0.9473 - val_accuracy: 0.8186 - val_loss: 0.9354\nEpoch 12/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 19ms/step - accuracy: 0.8231 - loss: 0.9399 - val_accuracy: 0.8180 - val_loss: 0.9286\nEpoch 13/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 19ms/step - accuracy: 0.8231 - loss: 0.9394 - val_accuracy: 0.8163 - val_loss: 0.9330\nEpoch 14/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 19ms/step - accuracy: 0.8249 - loss: 0.9341 - val_accuracy: 0.8213 - val_loss: 0.9250\nEpoch 15/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 19ms/step - accuracy: 0.8259 - loss: 0.9295 - val_accuracy: 0.8187 - val_loss: 0.9232\nEpoch 16/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 19ms/step - accuracy: 0.8234 - loss: 0.9344 - val_accuracy: 0.8192 - val_loss: 0.9272\nEpoch 17/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 19ms/step - accuracy: 0.8261 - loss: 0.9261 - val_accuracy: 0.8175 - val_loss: 0.9231\nEpoch 18/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 20ms/step - accuracy: 0.8256 - loss: 0.9279 - val_accuracy: 0.8177 - val_loss: 0.9229\nEpoch 19/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 20ms/step - accuracy: 0.8247 - loss: 0.9266 - val_accuracy: 0.8199 - val_loss: 0.9197\nEpoch 20/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 19ms/step - accuracy: 0.8247 - loss: 0.9269 - val_accuracy: 0.8186 - val_loss: 0.9217\nEpoch 21/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 19ms/step - accuracy: 0.8261 - loss: 0.9209 - val_accuracy: 0.8203 - val_loss: 0.9179\nEpoch 22/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 19ms/step - accuracy: 0.8261 - loss: 0.9217 - val_accuracy: 0.8202 - val_loss: 0.9199\nEpoch 23/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 19ms/step - accuracy: 0.8266 - loss: 0.9188 - val_accuracy: 0.8194 - val_loss: 0.9193\nEpoch 24/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 19ms/step - accuracy: 0.8266 - loss: 0.9196 - val_accuracy: 0.8189 - val_loss: 0.9200\nEpoch 25/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 19ms/step - accuracy: 0.8254 - loss: 0.9215 - val_accuracy: 0.8198 - val_loss: 0.9166\nEpoch 26/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 19ms/step - accuracy: 0.8257 - loss: 0.9210 - val_accuracy: 0.8201 - val_loss: 0.9145\nEpoch 27/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 19ms/step - accuracy: 0.8268 - loss: 0.9145 - val_accuracy: 0.8200 - val_loss: 0.9153\nEpoch 28/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 19ms/step - accuracy: 0.8277 - loss: 0.9145 - val_accuracy: 0.8188 - val_loss: 0.9159\nEpoch 29/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 19ms/step - accuracy: 0.8284 - loss: 0.9112 - val_accuracy: 0.8200 - val_loss: 0.9144\nEpoch 30/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 19ms/step - accuracy: 0.8263 - loss: 0.9186 - val_accuracy: 0.8201 - val_loss: 0.9142\nEpoch 31/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 19ms/step - accuracy: 0.8287 - loss: 0.9100 - val_accuracy: 0.8186 - val_loss: 0.9135\nEpoch 32/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 19ms/step - accuracy: 0.8295 - loss: 0.9079 - val_accuracy: 0.8194 - val_loss: 0.9148\nEpoch 33/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 19ms/step - accuracy: 0.8277 - loss: 0.9121 - val_accuracy: 0.8218 - val_loss: 0.9139\nEpoch 34/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 19ms/step - accuracy: 0.8281 - loss: 0.9099 - val_accuracy: 0.8198 - val_loss: 0.9165\nEpoch 35/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 19ms/step - accuracy: 0.8280 - loss: 0.9117 - val_accuracy: 0.8191 - val_loss: 0.9144\nEpoch 36/100\n\u001b[1m5627/5627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 19ms/step - accuracy: 0.8300 - loss: 0.9068 - val_accuracy: 0.8181 - val_loss: 0.9157\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533ms/step\nPredicted chord num: 8\nPredicted chord: Cmaj\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"chords = {\n    \"C Major\": [60, 64, 67, 72],\n    \"C Minor\": [60, 63, 67, 72],\n    \n    \"C# Major / Db Major\": [61, 65, 68, 73],\n    \"C# Minor / Db Minor\": [61, 64, 68, 73],\n    \n    \"D Major\": [62, 66, 69, 74],\n    \"D Minor\": [62, 65, 69, 74],\n    \n    \"D# Major / Eb Major\": [63, 67, 70, 75],\n    \"D# Minor / Eb Minor\": [63, 66, 70, 75],\n    \n    \"E Major\": [64, 68, 71, 76],\n    \"E Minor\": [64, 67, 71, 76],\n    \n    \"F Major\": [65, 69, 72, 77],\n    \"F Minor\": [65, 68, 72, 77],\n    \n    \"F# Major / Gb Major\": [66, 70, 73, 78],\n    \"F# Minor / Gb Minor\": [66, 69, 73, 78],\n    \n    \"G Major\": [67, 71, 74, 79],\n    \"G Minor\": [67, 70, 74, 79],\n    \n    \"G# Major / Ab Major\": [68, 72, 75, 80],\n    \"G# Minor / Ab Minor\": [68, 71, 75, 80],\n    \n    \"A Major\": [69, 73, 76, 81],\n    \"A Minor\": [69, 72, 76, 81],\n    \n    \"A# Major / Bb Major\": [70, 74, 77, 82],\n    \"A# Minor / Bb Minor\": [70, 73, 77, 82],\n    \n    \"B Major\": [71, 75, 78, 83],\n    \"B Minor\": [71, 74, 78, 83]\n}\n\nfor chord in chords.values():\n    pred_chord = predict_chord(model, chord)\n    print(chord_encodings[pred_chord])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T07:54:43.057479Z","iopub.execute_input":"2025-02-24T07:54:43.057849Z","iopub.status.idle":"2025-02-24T07:54:44.993328Z","shell.execute_reply.started":"2025-02-24T07:54:43.057823Z","shell.execute_reply":"2025-02-24T07:54:44.992375Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\nCmaj\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\nCmin\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\nC#maj\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\nC#min\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\nDmaj\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\nDmin\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\nD#maj\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\nD#min\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\nEmaj\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\nEmin\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\nFmaj\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\nFmin\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\nF#maj\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\nF#min\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\nGmaj\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\nGmin\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\nG#maj\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\nG#min\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\nAmaj\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\nAmin\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\nGmin\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\nA#min\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\nBmaj\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\nGmaj\n","output_type":"stream"}],"execution_count":28}]}