{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10480441,"sourceType":"datasetVersion","datasetId":6489604},{"sourceId":10768712,"sourceType":"datasetVersion","datasetId":6680282}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sharabhojha/chord-generation-lstm-example?scriptVersionId=223550702\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n!pip install liac-arff\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-20T11:06:53.252488Z","iopub.execute_input":"2025-02-20T11:06:53.252839Z","iopub.status.idle":"2025-02-20T11:07:02.707463Z","shell.execute_reply.started":"2025-02-20T11:06:53.252809Z","shell.execute_reply":"2025-02-20T11:07:02.70568Z"}},"outputs":[{"name":"stdout","text":"Collecting liac-arff\n  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nBuilding wheels for collected packages: liac-arff\n  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11716 sha256=0a66909fe754dc4ff9e7046906cb2d66bf48c8ba5387b9bd2827614ea1eb9fca\n  Stored in directory: /root/.cache/pip/wheels/5d/2a/9c/3895d9617f8f49a0883ba686326d598e78a1c2f54fe3cae86d\nSuccessfully built liac-arff\nInstalling collected packages: liac-arff\nSuccessfully installed liac-arff-2.5.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Preprocessing steps:\n# 1: condense onset files to just onset times and onset notes\n\nimport os\nimport re\nimport pandas as pd\nimport arff\n\n# Directory path to your annotations folder\nannotations_dir = \"/kaggle/input/aam-annotations/AAM-annotations/\"\nnum = 0\n\n# Iterate through all files in the directory\nfor filename in os.listdir(annotations_dir):\n    if \"onsets\" in filename and filename.endswith(\".arff\"):  # Ensure it's an ARFF file with 'onsets' in its name\n        num += 1\n        file_path = os.path.join(annotations_dir, filename)\n        \n        # Read the ARFF file\n        def read_arff(file_path):\n            with open(file_path, 'r') as f:\n                arff_data = arff.load(f)\n            return pd.DataFrame(arff_data['data'], columns=[attr[0] for attr in arff_data['attributes']])\n        \n        # Use this function instead of manual parsing\n        df = read_arff(file_path)\n\n        # Convert numeric columns where possible\n        for col in df.columns:\n            try:\n                df[col] = pd.to_numeric(df[col])  # Convert if possible\n            except ValueError:\n                pass  # Keep as string if conversion fails\n\n        all_onsets = []\n\n        # Vectorized operation to collect all onset events\n        onset_columns = df.columns[df.apply(lambda col: col.astype(str).str.contains(r\"\\[\", regex=True)).any()]\n        df[\"Onset events\"] = df[onset_columns].apply(lambda row: [int(x) for x in re.findall(r'\\d+', ''.join(row.astype(str)))], axis=1)\n        df.drop(onset_columns, axis=1, inplace=True)\n\n        # Save the processed DataFrame to a new CSV file\n        output_file = re.search(\"(\\d+)\", filename).group(0) + \"_onset_condensed.csv\"\n        df.to_csv(output_file, index=False)\n\n        if num % 100 == 0:\n            print(f\"Processed {filename} and saved to {output_file}\")","metadata":{"execution":{"iopub.status.busy":"2025-02-20T11:07:13.600457Z","iopub.execute_input":"2025-02-20T11:07:13.601243Z","iopub.status.idle":"2025-02-20T11:12:41.966853Z","shell.execute_reply.started":"2025-02-20T11:07:13.601209Z","shell.execute_reply":"2025-02-20T11:12:41.96575Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Processed 0521_onsets.arff and saved to 0521_onset_condensed.csv\nProcessed 2699_onsets.arff and saved to 2699_onset_condensed.csv\nProcessed 2634_onsets.arff and saved to 2634_onset_condensed.csv\nProcessed 0544_onsets.arff and saved to 0544_onset_condensed.csv\nProcessed 1658_onsets.arff and saved to 1658_onset_condensed.csv\nProcessed 1624_onsets.arff and saved to 1624_onset_condensed.csv\nProcessed 1192_onsets.arff and saved to 1192_onset_condensed.csv\nProcessed 0001_onsets.arff and saved to 0001_onset_condensed.csv\nProcessed 0382_onsets.arff and saved to 0382_onset_condensed.csv\nProcessed 1000_onsets.arff and saved to 1000_onset_condensed.csv\nProcessed 0541_onsets.arff and saved to 0541_onset_condensed.csv\nProcessed 1630_onsets.arff and saved to 1630_onset_condensed.csv\nProcessed 0696_onsets.arff and saved to 0696_onset_condensed.csv\nProcessed 0121_onsets.arff and saved to 0121_onset_condensed.csv\nProcessed 0097_onsets.arff and saved to 0097_onset_condensed.csv\nProcessed 0220_onsets.arff and saved to 0220_onset_condensed.csv\nProcessed 1161_onsets.arff and saved to 1161_onset_condensed.csv\nProcessed 2537_onsets.arff and saved to 2537_onset_condensed.csv\nProcessed 1108_onsets.arff and saved to 1108_onset_condensed.csv\nProcessed 0558_onsets.arff and saved to 0558_onset_condensed.csv\nProcessed 0564_onsets.arff and saved to 0564_onset_condensed.csv\nProcessed 2885_onsets.arff and saved to 2885_onset_condensed.csv\nProcessed 0646_onsets.arff and saved to 0646_onset_condensed.csv\nProcessed 2182_onsets.arff and saved to 2182_onset_condensed.csv\nProcessed 1541_onsets.arff and saved to 1541_onset_condensed.csv\nProcessed 1601_onsets.arff and saved to 1601_onset_condensed.csv\nProcessed 0352_onsets.arff and saved to 0352_onset_condensed.csv\nProcessed 1210_onsets.arff and saved to 1210_onset_condensed.csv\nProcessed 1189_onsets.arff and saved to 1189_onset_condensed.csv\nProcessed 2995_onsets.arff and saved to 2995_onset_condensed.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# 2: encode chord names and replace said chord names with encodings in beatinfo files\n\n# Directory path to your annotations folder\nheaders = ['Start time in seconds', 'Bar count', 'Quarter count', 'Chord name']\n\nchord_encodings = {0: 'A#maj', 1: 'A#min', 2: 'Amaj', 3: 'Amin', 4: 'Bmaj', 5: 'Bmin', 6: 'C#maj', 7: 'C#min', \n                   8: 'Cmaj', 9: 'Cmin', 10: 'D#maj', 11: 'D#min', 12: 'Dmaj', 13: 'Dmin', 14: 'Emaj', 15: 'Emin', \n                   16: 'F#maj', 17: 'F#min', 18: 'Fmaj', 19: 'Fmin', 20: 'G#maj', 21: 'G#min', 22: 'Gmaj', \n                   23: 'Gmin', 24: 'N.C.'}\n\ninverted_encodings = {'A#maj': 0, 'A#min': 1, 'Amaj': 2, 'Amin': 3, 'Bmaj': 4, 'Bmin': 5, 'C#maj': 6, 'C#min': 7, \n                   'Cmaj': 8, 'Cmin': 9, 'D#maj': 10, 'D#min': 11, 'Dmaj': 12, 'Dmin': 13, 'Emaj': 14, 'Emin': 15, \n                   'F#maj': 16, 'F#min': 17, 'Fmaj': 18, 'Fmin': 19, 'G#maj': 20, 'G#min': 21, 'Gmaj': 22, \n                   'Gmin': 23, 'N.C.': 24}\n\ndataframes = []\nfilenames = []\n\n# Iterate through all files in the directory\nfor filename in os.listdir(annotations_dir):\n    if \"beatinfo\" in filename and filename.endswith(\".arff\"):  # Ensure it's an ARFF file with 'beatinfo' in its name\n        file_path = os.path.join(annotations_dir, filename)\n        filenames.append(filename)\n        df = pd.read_csv(file_path, comment='@', header=None)\n        df.columns = headers\n\n        for i in range(df.index.size):\n            df.iat[i, 3] = df.iat[i, 3].replace(\"'\", \"\")\n            if df.iat[i, 3] == \"BASS_NOTE_EXCEPTION\":\n                df.iat[i, 3] = \"N.C.\"\n            df.iat[i, 3] = inverted_encodings[df.iat[i, 3]]\n    \n        df.to_csv(filename.replace('arff', 'csv'), index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T11:12:55.013647Z","iopub.execute_input":"2025-02-20T11:12:55.014011Z","iopub.status.idle":"2025-02-20T11:14:26.414956Z","shell.execute_reply.started":"2025-02-20T11:12:55.013979Z","shell.execute_reply":"2025-02-20T11:14:26.413639Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# visualize the files\nworking_dir = \"/kaggle/working/\"\nonsets = pd.read_csv(working_dir + \"0001_onset_condensed.csv\")\nprint(onsets.head())\nbeatinfo = pd.read_csv(working_dir + \"0001_beatinfo.csv\")\nprint(beatinfo.head())\n\ndef align_onsets_with_chords(onsets, beatinfo):\n    aligned_data = []\n    for _, onset_row in onsets.iterrows():\n        onset_time = onset_row['Onset time in seconds']\n        # Find the chord corresponding to this onset time\n        chord_row = beatinfo[beatinfo['Start time in seconds'] <= onset_time].iloc[-1]\n        onset_list = eval(onset_row['Onset events'])\n        aligned_data.append((onset_list, chord_row['Chord name']))\n    return aligned_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T11:15:02.327626Z","iopub.execute_input":"2025-02-20T11:15:02.327952Z","iopub.status.idle":"2025-02-20T11:15:02.347912Z","shell.execute_reply.started":"2025-02-20T11:15:02.327928Z","shell.execute_reply":"2025-02-20T11:15:02.346615Z"}},"outputs":[{"name":"stdout","text":"   Onset time in seconds  Onset events\n0               0.000000  [41, 60, 65]\n1               0.326086      [41, 60]\n2               0.652173  [41, 65, 65]\n3               0.978259  [41, 65, 69]\n4               1.304346  [41, 65, 65]\n   Start time in seconds  Bar count  Quarter count  Chord name\n0               0.000000          1              1          18\n1               0.652174          1              2          18\n2               1.304348          1              3          18\n3               1.956522          1              4          18\n4               2.608696          2              1           0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# create aligned data for every onset and beatinfo file\n\nall_data = []\n\nfor filename in os.listdir(working_dir):\n    if \"onset\" in filename:\n        onset_path = os.path.join(working_dir, filename)\n        beatinfo_path = os.path.join(working_dir, re.search(\"(\\d+)\", filename).group(0) + \"_beatinfo.csv\")\n        onsets = pd.read_csv(onset_path)\n        beatinfo = pd.read_csv(beatinfo_path)\n        all_data += align_onsets_with_chords(onsets, beatinfo)\n\nprint(len(all_data))\nprint(all_data[0:20])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T11:15:12.389704Z","iopub.execute_input":"2025-02-20T11:15:12.390075Z","iopub.status.idle":"2025-02-20T11:30:31.261427Z","shell.execute_reply.started":"2025-02-20T11:15:12.390045Z","shell.execute_reply":"2025-02-20T11:30:31.260085Z"}},"outputs":[{"name":"stdout","text":"1712284\n[([36, 42, 53, 56, 61, 37, 65], 6.0), ([36, 44, 53, 56, 61, 37, 61], 6.0), ([37, 44, 53, 56, 61, 37, 68], 6.0), ([36, 44, 53, 56, 61, 37, 65], 6.0), ([36, 44, 53, 56, 61, 37, 61], 6.0), ([36, 44, 53, 56, 61, 37, 68], 6.0), ([36, 37, 44, 53, 56, 61, 37, 61], 6.0), ([36, 44, 53, 56, 61, 37, 68], 6.0), ([36, 44, 51, 56, 60, 44, 60], 6.0), ([36, 44, 51, 56, 60, 44, 68], 20.0), ([37, 44, 51, 56, 60, 44, 63], 20.0), ([36, 44, 51, 56, 60, 44, 60], 20.0), ([36, 44, 51, 56, 60, 44, 68], 20.0), ([36, 44, 51, 56, 60, 44, 63], 20.0), ([36, 37, 44, 51, 56, 60, 44, 68], 20.0), ([36, 44, 51, 56, 60, 44, 63], 20.0), ([36, 44, 51, 55, 58, 39, 67], 20.0), ([36, 44, 51, 55, 58, 39, 63], 10.0), ([37, 44, 51, 55, 58, 39, 70], 10.0), ([36, 44, 51, 55, 58, 39, 67], 10.0)]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Embedding, LSTM, Dense, TimeDistributed, BatchNormalization\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\n\ndef create_chord_classification_model(vocab_size, embedding_dim, lstm_units, num_classes, max_sequence_length):\n    # Input for note sequences\n    note_input = Input(shape=(max_sequence_length,))\n    \n    # Embedding layer for note sequences\n    note_embedding = Embedding(vocab_size, embedding_dim)(note_input)\n    \n    # LSTM layers\n    lstm_output = LSTM(lstm_units, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(note_embedding) # with more lstm layers, return sequences = true\n    lstm_output = BatchNormalization()(lstm_output)\n    lstm_output = LSTM(lstm_units, return_sequences=False, dropout=0.2, recurrent_dropout=0.2)(lstm_output)\n    \n    # Output layer\n    output = Dense(num_classes, activation='softmax', kernel_regularizer=l2(0.01))(lstm_output)\n    \n    model = Model(inputs=note_input, outputs=output)\n    return model\n\n# Hyperparameters\nvocab_size = 128  # Assuming MIDI note range\nembedding_dim = 32\nlstm_units = 64\nnum_classes = 25  # Number of chord classes\nmax_sequence_length = 16  # Adjust based on your data\n\n# Create the model\nmodel = create_chord_classification_model(vocab_size, embedding_dim, lstm_units, num_classes, max_sequence_length)\n\n# Compile the model\noptimizer = Adam(learning_rate=0.0001)\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Function to prepare data\ndef prepare_data(data, max_sequence_length):\n    X = []\n    y = []\n    for sequence in data:\n        notes, chord = sequence\n        padded_notes = tf.keras.preprocessing.sequence.pad_sequences([notes], maxlen=max_sequence_length, padding='post', truncating='post')[0]\n        X.append(padded_notes)\n        y.append(chord)\n    return np.array(X), np.array(y)\n\n# Prepare your data\nX, y = prepare_data(all_data[0:20000], max_sequence_length)\n\n# Convert y to one-hot encoded format\ny_onehot = tf.keras.utils.to_categorical(y, num_classes=num_classes)\n\n# Train the model\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\nhistory = model.fit(X, y_onehot, validation_split=0.2, epochs=100, batch_size=32, callbacks=[early_stopping])\n\n# Function for inference\ndef predict_chord(model, note_sequence):\n    padded_sequence = tf.keras.preprocessing.sequence.pad_sequences([note_sequence], maxlen=max_sequence_length, padding='post', truncating='post')\n    predictions = model.predict(padded_sequence)\n    return np.argmax(predictions[0])  # Return the prediction\n\n# Example usage\nsample_sequence = [60, 64, 67, 72]  # C major chor\npredicted_chord = predict_chord(model, sample_sequence)\nprint(f\"Predicted chord num: {predicted_chord}\")\nprint(f\"Predicted chord: {chord_encodings[predicted_chord]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T11:38:03.282833Z","iopub.execute_input":"2025-02-20T11:38:03.28322Z","iopub.status.idle":"2025-02-20T11:44:11.238095Z","shell.execute_reply.started":"2025-02-20T11:38:03.283191Z","shell.execute_reply":"2025-02-20T11:44:11.236683Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - accuracy: 0.1201 - loss: 3.4457 - val_accuracy: 0.3610 - val_loss: 2.7517\nEpoch 2/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.4573 - loss: 2.2731 - val_accuracy: 0.5030 - val_loss: 2.0627\nEpoch 3/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.5795 - loss: 1.8556 - val_accuracy: 0.6083 - val_loss: 1.8099\nEpoch 4/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.6401 - loss: 1.6771 - val_accuracy: 0.6735 - val_loss: 1.6656\nEpoch 5/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.6760 - loss: 1.5596 - val_accuracy: 0.6985 - val_loss: 1.5978\nEpoch 6/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7028 - loss: 1.4781 - val_accuracy: 0.7055 - val_loss: 1.5624\nEpoch 7/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.7279 - loss: 1.3966 - val_accuracy: 0.7160 - val_loss: 1.4955\nEpoch 8/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.7274 - loss: 1.3851 - val_accuracy: 0.7308 - val_loss: 1.4523\nEpoch 9/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.7235 - loss: 1.3909 - val_accuracy: 0.7250 - val_loss: 1.4450\nEpoch 10/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.7500 - loss: 1.3084 - val_accuracy: 0.7262 - val_loss: 1.4217\nEpoch 11/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.7524 - loss: 1.2946 - val_accuracy: 0.7380 - val_loss: 1.3995\nEpoch 12/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.7614 - loss: 1.2565 - val_accuracy: 0.7523 - val_loss: 1.3678\nEpoch 13/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7715 - loss: 1.2222 - val_accuracy: 0.7448 - val_loss: 1.3548\nEpoch 14/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.7751 - loss: 1.2029 - val_accuracy: 0.7490 - val_loss: 1.3443\nEpoch 15/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7764 - loss: 1.1912 - val_accuracy: 0.7580 - val_loss: 1.3278\nEpoch 16/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7816 - loss: 1.1579 - val_accuracy: 0.7635 - val_loss: 1.3078\nEpoch 17/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7843 - loss: 1.1552 - val_accuracy: 0.7550 - val_loss: 1.3117\nEpoch 18/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7798 - loss: 1.1598 - val_accuracy: 0.7648 - val_loss: 1.2850\nEpoch 19/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7945 - loss: 1.1189 - val_accuracy: 0.7665 - val_loss: 1.2709\nEpoch 20/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7902 - loss: 1.1216 - val_accuracy: 0.7595 - val_loss: 1.2965\nEpoch 21/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7953 - loss: 1.1138 - val_accuracy: 0.7635 - val_loss: 1.2691\nEpoch 22/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7904 - loss: 1.1139 - val_accuracy: 0.7605 - val_loss: 1.2802\nEpoch 23/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7961 - loss: 1.1089 - val_accuracy: 0.7670 - val_loss: 1.2553\nEpoch 24/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.7933 - loss: 1.1090 - val_accuracy: 0.7710 - val_loss: 1.2345\nEpoch 25/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.8021 - loss: 1.0676 - val_accuracy: 0.7713 - val_loss: 1.2358\nEpoch 26/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7993 - loss: 1.0805 - val_accuracy: 0.7707 - val_loss: 1.2278\nEpoch 27/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.8065 - loss: 1.0638 - val_accuracy: 0.7682 - val_loss: 1.2328\nEpoch 28/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8028 - loss: 1.0652 - val_accuracy: 0.7705 - val_loss: 1.2215\nEpoch 29/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8055 - loss: 1.0546 - val_accuracy: 0.7732 - val_loss: 1.2120\nEpoch 30/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.8060 - loss: 1.0406 - val_accuracy: 0.7830 - val_loss: 1.2052\nEpoch 31/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8104 - loss: 1.0354 - val_accuracy: 0.7765 - val_loss: 1.2135\nEpoch 32/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8127 - loss: 1.0203 - val_accuracy: 0.7835 - val_loss: 1.1899\nEpoch 33/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.8120 - loss: 1.0189 - val_accuracy: 0.7750 - val_loss: 1.2005\nEpoch 34/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8112 - loss: 1.0275 - val_accuracy: 0.7742 - val_loss: 1.2056\nEpoch 35/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8191 - loss: 1.0009 - val_accuracy: 0.7785 - val_loss: 1.1997\nEpoch 36/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.8229 - loss: 0.9891 - val_accuracy: 0.7730 - val_loss: 1.2007\nEpoch 37/100\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.8214 - loss: 0.9930 - val_accuracy: 0.7793 - val_loss: 1.2010\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step\nPredicted chord num: 8\nPredicted chord: Cmaj\n","output_type":"stream"}],"execution_count":8}]}