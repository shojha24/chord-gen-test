{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sharabhojha/chord-generation-lstm-example?scriptVersionId=223561399\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"351d0f90","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-02-20T13:00:56.805311Z","iopub.status.busy":"2025-02-20T13:00:56.804827Z","iopub.status.idle":"2025-02-20T13:01:06.676759Z","shell.execute_reply":"2025-02-20T13:01:06.675476Z"},"papermill":{"duration":9.878372,"end_time":"2025-02-20T13:01:06.678741","exception":false,"start_time":"2025-02-20T13:00:56.800369","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting liac-arff\r\n","  Downloading liac-arff-2.5.0.tar.gz (13 kB)\r\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n","Building wheels for collected packages: liac-arff\r\n","  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n","  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11716 sha256=42dd76c1a5264265bb9be17210a967a96a98006032c9ae03fce7f9b214d5dd99\r\n","  Stored in directory: /root/.cache/pip/wheels/5d/2a/9c/3895d9617f8f49a0883ba686326d598e78a1c2f54fe3cae86d\r\n","Successfully built liac-arff\r\n","Installing collected packages: liac-arff\r\n","Successfully installed liac-arff-2.5.0\r\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","!pip install liac-arff\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"id":"0da2eeaf","metadata":{"execution":{"iopub.execute_input":"2025-02-20T13:01:06.686507Z","iopub.status.busy":"2025-02-20T13:01:06.68576Z","iopub.status.idle":"2025-02-20T13:07:00.758108Z","shell.execute_reply":"2025-02-20T13:07:00.756725Z"},"papermill":{"duration":354.081974,"end_time":"2025-02-20T13:07:00.763888","exception":false,"start_time":"2025-02-20T13:01:06.681914","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Processed 0521_onsets.arff and saved to 0521_onset_condensed.csv\n","Processed 2699_onsets.arff and saved to 2699_onset_condensed.csv\n","Processed 2634_onsets.arff and saved to 2634_onset_condensed.csv\n","Processed 0544_onsets.arff and saved to 0544_onset_condensed.csv\n","Processed 1658_onsets.arff and saved to 1658_onset_condensed.csv\n","Processed 1624_onsets.arff and saved to 1624_onset_condensed.csv\n","Processed 1192_onsets.arff and saved to 1192_onset_condensed.csv\n","Processed 0001_onsets.arff and saved to 0001_onset_condensed.csv\n","Processed 0382_onsets.arff and saved to 0382_onset_condensed.csv\n","Processed 1000_onsets.arff and saved to 1000_onset_condensed.csv\n","Processed 0541_onsets.arff and saved to 0541_onset_condensed.csv\n","Processed 1630_onsets.arff and saved to 1630_onset_condensed.csv\n","Processed 0696_onsets.arff and saved to 0696_onset_condensed.csv\n","Processed 0121_onsets.arff and saved to 0121_onset_condensed.csv\n","Processed 0097_onsets.arff and saved to 0097_onset_condensed.csv\n","Processed 0220_onsets.arff and saved to 0220_onset_condensed.csv\n","Processed 1161_onsets.arff and saved to 1161_onset_condensed.csv\n","Processed 2537_onsets.arff and saved to 2537_onset_condensed.csv\n","Processed 1108_onsets.arff and saved to 1108_onset_condensed.csv\n","Processed 0558_onsets.arff and saved to 0558_onset_condensed.csv\n","Processed 0564_onsets.arff and saved to 0564_onset_condensed.csv\n","Processed 2885_onsets.arff and saved to 2885_onset_condensed.csv\n","Processed 0646_onsets.arff and saved to 0646_onset_condensed.csv\n","Processed 2182_onsets.arff and saved to 2182_onset_condensed.csv\n","Processed 1541_onsets.arff and saved to 1541_onset_condensed.csv\n","Processed 1601_onsets.arff and saved to 1601_onset_condensed.csv\n","Processed 0352_onsets.arff and saved to 0352_onset_condensed.csv\n","Processed 1210_onsets.arff and saved to 1210_onset_condensed.csv\n","Processed 1189_onsets.arff and saved to 1189_onset_condensed.csv\n","Processed 2995_onsets.arff and saved to 2995_onset_condensed.csv\n"]}],"source":["# Preprocessing steps:\n","# 1: condense onset files to just onset times and onset notes\n","\n","import os\n","import re\n","import pandas as pd\n","import arff\n","\n","# Directory path to your annotations folder\n","annotations_dir = \"/kaggle/input/aam-annotations/AAM-annotations/\"\n","num = 0\n","\n","# Iterate through all files in the directory\n","for filename in os.listdir(annotations_dir):\n","    if \"onsets\" in filename and filename.endswith(\".arff\"):  # Ensure it's an ARFF file with 'onsets' in its name\n","        num += 1\n","        file_path = os.path.join(annotations_dir, filename)\n","        \n","        # Read the ARFF file\n","        def read_arff(file_path):\n","            with open(file_path, 'r') as f:\n","                arff_data = arff.load(f)\n","            return pd.DataFrame(arff_data['data'], columns=[attr[0] for attr in arff_data['attributes']])\n","        \n","        # Use this function instead of manual parsing\n","        df = read_arff(file_path)\n","\n","        # Convert numeric columns where possible\n","        for col in df.columns:\n","            try:\n","                df[col] = pd.to_numeric(df[col])  # Convert if possible\n","            except ValueError:\n","                pass  # Keep as string if conversion fails\n","\n","        all_onsets = []\n","\n","        # Vectorized operation to collect all onset events\n","        onset_columns = df.columns[df.apply(lambda col: col.astype(str).str.contains(r\"\\[\", regex=True)).any()]\n","        df[\"Onset events\"] = df[onset_columns].apply(lambda row: [int(x) for x in re.findall(r'\\d+', ''.join(row.astype(str)))], axis=1)\n","        df.drop(onset_columns, axis=1, inplace=True)\n","\n","        # Save the processed DataFrame to a new CSV file\n","        output_file = re.search(\"(\\d+)\", filename).group(0) + \"_onset_condensed.csv\"\n","        df.to_csv(output_file, index=False)\n","\n","        if num % 100 == 0:\n","            print(f\"Processed {filename} and saved to {output_file}\")"]},{"cell_type":"code","execution_count":3,"id":"67350392","metadata":{"execution":{"iopub.execute_input":"2025-02-20T13:07:00.774404Z","iopub.status.busy":"2025-02-20T13:07:00.773892Z","iopub.status.idle":"2025-02-20T13:08:45.957021Z","shell.execute_reply":"2025-02-20T13:08:45.955172Z"},"papermill":{"duration":105.191012,"end_time":"2025-02-20T13:08:45.959402","exception":false,"start_time":"2025-02-20T13:07:00.76839","status":"completed"},"tags":[]},"outputs":[],"source":["# 2: encode chord names and replace said chord names with encodings in beatinfo files\n","\n","# Directory path to your annotations folder\n","headers = ['Start time in seconds', 'Bar count', 'Quarter count', 'Chord name']\n","\n","chord_encodings = {0: 'A#maj', 1: 'A#min', 2: 'Amaj', 3: 'Amin', 4: 'Bmaj', 5: 'Bmin', 6: 'C#maj', 7: 'C#min', \n","                   8: 'Cmaj', 9: 'Cmin', 10: 'D#maj', 11: 'D#min', 12: 'Dmaj', 13: 'Dmin', 14: 'Emaj', 15: 'Emin', \n","                   16: 'F#maj', 17: 'F#min', 18: 'Fmaj', 19: 'Fmin', 20: 'G#maj', 21: 'G#min', 22: 'Gmaj', \n","                   23: 'Gmin', 24: 'N.C.'}\n","\n","inverted_encodings = {'A#maj': 0, 'A#min': 1, 'Amaj': 2, 'Amin': 3, 'Bmaj': 4, 'Bmin': 5, 'C#maj': 6, 'C#min': 7, \n","                   'Cmaj': 8, 'Cmin': 9, 'D#maj': 10, 'D#min': 11, 'Dmaj': 12, 'Dmin': 13, 'Emaj': 14, 'Emin': 15, \n","                   'F#maj': 16, 'F#min': 17, 'Fmaj': 18, 'Fmin': 19, 'G#maj': 20, 'G#min': 21, 'Gmaj': 22, \n","                   'Gmin': 23, 'N.C.': 24}\n","\n","# Iterate through all files in the directory\n","for filename in os.listdir(annotations_dir):\n","    if \"beatinfo\" in filename and filename.endswith(\".arff\"):  # Ensure it's an ARFF file with 'beatinfo' in its name\n","        file_path = os.path.join(annotations_dir, filename)\n","        df = pd.read_csv(file_path, comment='@', header=None)\n","        df.columns = headers\n","\n","        for i in range(df.index.size):\n","            df.iat[i, 3] = df.iat[i, 3].replace(\"'\", \"\")\n","            if df.iat[i, 3] == \"BASS_NOTE_EXCEPTION\":\n","                df.iat[i, 3] = \"N.C.\"\n","            df.iat[i, 3] = inverted_encodings[df.iat[i, 3]]\n","    \n","        df.to_csv(filename.replace('arff', 'csv'), index=False)"]},{"cell_type":"code","execution_count":4,"id":"ee406c00","metadata":{"execution":{"iopub.execute_input":"2025-02-20T13:08:45.970404Z","iopub.status.busy":"2025-02-20T13:08:45.97006Z","iopub.status.idle":"2025-02-20T13:08:45.989978Z","shell.execute_reply":"2025-02-20T13:08:45.988636Z"},"papermill":{"duration":0.027506,"end_time":"2025-02-20T13:08:45.991795","exception":false,"start_time":"2025-02-20T13:08:45.964289","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["   Onset time in seconds  Onset events\n","0               0.000000  [41, 60, 65]\n","1               0.326086      [41, 60]\n","2               0.652173  [41, 65, 65]\n","3               0.978259  [41, 65, 69]\n","4               1.304346  [41, 65, 65]\n","   Start time in seconds  Bar count  Quarter count  Chord name\n","0               0.000000          1              1          18\n","1               0.652174          1              2          18\n","2               1.304348          1              3          18\n","3               1.956522          1              4          18\n","4               2.608696          2              1           0\n"]}],"source":["# visualize the files\n","working_dir = \"/kaggle/working/\"\n","onsets = pd.read_csv(working_dir + \"0001_onset_condensed.csv\")\n","print(onsets.head())\n","beatinfo = pd.read_csv(working_dir + \"0001_beatinfo.csv\")\n","print(beatinfo.head())\n","\n","def align_onsets_with_chords(onsets, beatinfo):\n","    aligned_data = []\n","    for _, onset_row in onsets.iterrows():\n","        onset_time = onset_row['Onset time in seconds']\n","        # Find the chord corresponding to this onset time\n","        chord_row = beatinfo[beatinfo['Start time in seconds'] <= onset_time].iloc[-1]\n","        onset_list = eval(onset_row['Onset events'])\n","        aligned_data.append((onset_list, chord_row['Chord name']))\n","    return aligned_data"]},{"cell_type":"code","execution_count":5,"id":"cda85d96","metadata":{"execution":{"iopub.execute_input":"2025-02-20T13:08:46.002441Z","iopub.status.busy":"2025-02-20T13:08:46.002112Z","iopub.status.idle":"2025-02-20T13:23:47.329939Z","shell.execute_reply":"2025-02-20T13:23:47.328708Z"},"papermill":{"duration":901.338892,"end_time":"2025-02-20T13:23:47.33541","exception":false,"start_time":"2025-02-20T13:08:45.996518","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["3000\n"]}],"source":["# create aligned data for every onset and beatinfo file\n","\n","all_data = []\n","i = 0\n","\n","while i < 3000:\n","    i += 1\n","    onset_path = os.path.join(working_dir, f\"{i :04d}_onset_condensed.csv\")\n","    beatinfo_path = os.path.join(working_dir, f\"{i :04d}_beatinfo.csv\")\n","    onsets = pd.read_csv(onset_path)\n","    beatinfo = pd.read_csv(beatinfo_path)\n","    all_data.append(align_onsets_with_chords(onsets, beatinfo))\n","\n","\"\"\"for filename in os.listdir(working_dir):\n","    if \"onset\" in filename:\n","        onset_path = os.path.join(working_dir, filename)\n","        beatinfo_path = os.path.join(working_dir, re.search(\"(\\d+)\", filename).group(0) + \"_beatinfo.csv\")\n","        onsets = pd.read_csv(onset_path)\n","        beatinfo = pd.read_csv(beatinfo_path)\n","        all_data.append(align_onsets_with_chords(onsets, beatinfo))\"\"\"\n","\n","print(len(all_data))\n","#print(all_data[0:20])"]},{"cell_type":"code","execution_count":6,"id":"dd4b56a5","metadata":{"execution":{"iopub.execute_input":"2025-02-20T13:23:47.346716Z","iopub.status.busy":"2025-02-20T13:23:47.346306Z","iopub.status.idle":"2025-02-20T13:30:03.246149Z","shell.execute_reply":"2025-02-20T13:30:03.244678Z"},"papermill":{"duration":375.907885,"end_time":"2025-02-20T13:30:03.248295","exception":false,"start_time":"2025-02-20T13:23:47.34041","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Total training sequences: 19701\n","Total testing sequences: 5136\n","Epoch 1/100\n","\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - accuracy: 0.0891 - loss: 3.4323 - val_accuracy: 0.2755 - val_loss: 2.8188\n","Epoch 2/100\n","\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.4144 - loss: 2.4021 - val_accuracy: 0.5360 - val_loss: 1.9971\n","Epoch 3/100\n","\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.5592 - loss: 1.9435 - val_accuracy: 0.6088 - val_loss: 1.7459\n","Epoch 4/100\n","\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - accuracy: 0.6222 - loss: 1.7319 - val_accuracy: 0.6460 - val_loss: 1.6118\n","Epoch 5/100\n","\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.6510 - loss: 1.6258 - val_accuracy: 0.7050 - val_loss: 1.4880\n","Epoch 6/100\n","\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.6740 - loss: 1.5337 - val_accuracy: 0.7356 - val_loss: 1.4255\n","Epoch 7/100\n","\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.6993 - loss: 1.4735 - val_accuracy: 0.7481 - val_loss: 1.3856\n","Epoch 8/100\n","\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.6970 - loss: 1.4454 - val_accuracy: 0.7243 - val_loss: 1.3453\n","Epoch 9/100\n","\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 22ms/step - accuracy: 0.7097 - loss: 1.4051 - val_accuracy: 0.7262 - val_loss: 1.3334\n","Epoch 10/100\n","\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.7190 - loss: 1.3632 - val_accuracy: 0.7225 - val_loss: 1.3199\n","Epoch 11/100\n","\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.7315 - loss: 1.3312 - val_accuracy: 0.7416 - val_loss: 1.2799\n","Epoch 12/100\n","\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.7344 - loss: 1.3166 - val_accuracy: 0.7516 - val_loss: 1.2588\n","Epoch 13/100\n","\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.7393 - loss: 1.2853 - val_accuracy: 0.7313 - val_loss: 1.2753\n","Epoch 14/100\n","\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.7397 - loss: 1.2764 - val_accuracy: 0.7370 - val_loss: 1.2490\n","Epoch 15/100\n","\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.7420 - loss: 1.2669 - val_accuracy: 0.7410 - val_loss: 1.2477\n","Epoch 16/100\n","\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.7459 - loss: 1.2430 - val_accuracy: 0.7426 - val_loss: 1.2369\n","Epoch 17/100\n","\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 20ms/step - accuracy: 0.7475 - loss: 1.2254 - val_accuracy: 0.7459 - val_loss: 1.2309\n","Epoch 18/100\n","\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.7442 - loss: 1.2375 - val_accuracy: 0.7494 - val_loss: 1.2325\n","Epoch 19/100\n","\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.7544 - loss: 1.2060 - val_accuracy: 0.7438 - val_loss: 1.2246\n","Epoch 20/100\n","\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.7559 - loss: 1.1964 - val_accuracy: 0.7535 - val_loss: 1.2134\n","Epoch 21/100\n","\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.7628 - loss: 1.1735 - val_accuracy: 0.7648 - val_loss: 1.1889\n","Epoch 22/100\n","\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.7655 - loss: 1.1746 - val_accuracy: 0.7615 - val_loss: 1.1802\n","Epoch 23/100\n","\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.7654 - loss: 1.1680 - val_accuracy: 0.7547 - val_loss: 1.2038\n","Epoch 24/100\n","\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.7677 - loss: 1.1612 - val_accuracy: 0.7475 - val_loss: 1.2047\n","Epoch 25/100\n","\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 20ms/step - accuracy: 0.7754 - loss: 1.1344 - val_accuracy: 0.7613 - val_loss: 1.1876\n","Epoch 26/100\n","\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.7792 - loss: 1.1161 - val_accuracy: 0.7434 - val_loss: 1.2021\n","Epoch 27/100\n","\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.7775 - loss: 1.1227 - val_accuracy: 0.7469 - val_loss: 1.2013\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step\n","Predicted chord num: 8\n","Predicted chord: Cmaj\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, TimeDistributed, BatchNormalization\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","\n","def create_chord_classification_model(vocab_size, embedding_dim, lstm_units, num_classes, max_sequence_length):\n","    # Input for note sequences\n","    note_input = Input(shape=(max_sequence_length,))\n","    \n","    # Embedding layer for note sequences\n","    note_embedding = Embedding(vocab_size, embedding_dim)(note_input)\n","    \n","    # LSTM layers\n","    lstm_output = LSTM(lstm_units, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(note_embedding) # with more lstm layers, return sequences = true\n","    lstm_output = BatchNormalization()(lstm_output)\n","    lstm_output = LSTM(lstm_units, return_sequences=False, dropout=0.2, recurrent_dropout=0.2)(lstm_output)\n","    \n","    # Output layer\n","    output = Dense(num_classes, activation='softmax', kernel_regularizer=l2(0.01))(lstm_output)\n","    \n","    model = Model(inputs=note_input, outputs=output)\n","    return model\n","\n","# Hyperparameters\n","vocab_size = 128  # Assuming MIDI note range\n","embedding_dim = 32\n","lstm_units = 64\n","num_classes = 25  # Number of chord classes\n","max_sequence_length = 16  # Adjust based on your data\n","\n","# Create the model\n","model = create_chord_classification_model(vocab_size, embedding_dim, lstm_units, num_classes, max_sequence_length)\n","\n","# Compile the model\n","optimizer = Adam(learning_rate=0.0001)\n","model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Split at the song level (here I can decide how many of the songs I want to use)\n","train_songs, test_songs = train_test_split(all_data[0:40], test_size=0.2, random_state=42)\n","\n","# Flatten sequences within each split\n","train_data = [pair for song in train_songs for pair in song]  # Keep full song sequences together\n","test_data = [pair for song in test_songs for pair in song]\n","\n","print(f\"Total training sequences: {len(train_data)}\")\n","print(f\"Total testing sequences: {len(test_data)}\")\n","\n","# Function to prepare data\n","def prepare_data(data, max_sequence_length):\n","    X, y = [], []\n","    for notes, chord in data:\n","        padded_notes = tf.keras.preprocessing.sequence.pad_sequences([notes], maxlen=max_sequence_length, padding='post', truncating='post')[0]\n","        X.append(padded_notes)\n","        y.append(chord)\n","    return np.array(X), np.array(y)\n","\n","# Prepare train and test data\n","X_train, y_train = prepare_data(train_data, max_sequence_length)\n","X_test, y_test = prepare_data(test_data, max_sequence_length)\n","\n","# Convert y to one-hot encoding\n","y_train_onehot = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n","y_test_onehot = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)\n","\n","# Train the model\n","early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","history = model.fit(X_train, y_train_onehot, validation_data=(X_test, y_test_onehot), epochs=100, batch_size=32, callbacks=[early_stopping])\n","\n","# Function for inference\n","def predict_chord(model, note_sequence):\n","    padded_sequence = tf.keras.preprocessing.sequence.pad_sequences([note_sequence], maxlen=max_sequence_length, padding='post', truncating='post')\n","    predictions = model.predict(padded_sequence)\n","    return np.argmax(predictions[0])  # Return the prediction\n","\n","# Example usage\n","sample_sequence = [60, 64, 67, 72]  # C major chor\n","predicted_chord = predict_chord(model, sample_sequence)\n","print(f\"Predicted chord num: {predicted_chord}\")\n","print(f\"Predicted chord: {chord_encodings[predicted_chord]}\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":6489604,"sourceId":10480441,"sourceType":"datasetVersion"},{"datasetId":6680282,"sourceId":10768712,"sourceType":"datasetVersion"}],"dockerImageVersionId":30839,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":1752.647817,"end_time":"2025-02-20T13:30:06.350641","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-02-20T13:00:53.702824","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}