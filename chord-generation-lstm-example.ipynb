{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10480441,"sourceType":"datasetVersion","datasetId":6489604},{"sourceId":10768712,"sourceType":"datasetVersion","datasetId":6680282}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sharabhojha/chord-generation-lstm-example?scriptVersionId=223555318\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n!pip install liac-arff\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-20T11:06:53.252488Z","iopub.execute_input":"2025-02-20T11:06:53.252839Z","iopub.status.idle":"2025-02-20T11:07:02.707463Z","shell.execute_reply.started":"2025-02-20T11:06:53.252809Z","shell.execute_reply":"2025-02-20T11:07:02.70568Z"}},"outputs":[{"name":"stdout","text":"Collecting liac-arff\n  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nBuilding wheels for collected packages: liac-arff\n  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11716 sha256=0a66909fe754dc4ff9e7046906cb2d66bf48c8ba5387b9bd2827614ea1eb9fca\n  Stored in directory: /root/.cache/pip/wheels/5d/2a/9c/3895d9617f8f49a0883ba686326d598e78a1c2f54fe3cae86d\nSuccessfully built liac-arff\nInstalling collected packages: liac-arff\nSuccessfully installed liac-arff-2.5.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Preprocessing steps:\n# 1: condense onset files to just onset times and onset notes\n\nimport os\nimport re\nimport pandas as pd\nimport arff\n\n# Directory path to your annotations folder\nannotations_dir = \"/kaggle/input/aam-annotations/AAM-annotations/\"\nnum = 0\n\n# Iterate through all files in the directory\nfor filename in os.listdir(annotations_dir):\n    if \"onsets\" in filename and filename.endswith(\".arff\"):  # Ensure it's an ARFF file with 'onsets' in its name\n        num += 1\n        file_path = os.path.join(annotations_dir, filename)\n        \n        # Read the ARFF file\n        def read_arff(file_path):\n            with open(file_path, 'r') as f:\n                arff_data = arff.load(f)\n            return pd.DataFrame(arff_data['data'], columns=[attr[0] for attr in arff_data['attributes']])\n        \n        # Use this function instead of manual parsing\n        df = read_arff(file_path)\n\n        # Convert numeric columns where possible\n        for col in df.columns:\n            try:\n                df[col] = pd.to_numeric(df[col])  # Convert if possible\n            except ValueError:\n                pass  # Keep as string if conversion fails\n\n        all_onsets = []\n\n        # Vectorized operation to collect all onset events\n        onset_columns = df.columns[df.apply(lambda col: col.astype(str).str.contains(r\"\\[\", regex=True)).any()]\n        df[\"Onset events\"] = df[onset_columns].apply(lambda row: [int(x) for x in re.findall(r'\\d+', ''.join(row.astype(str)))], axis=1)\n        df.drop(onset_columns, axis=1, inplace=True)\n\n        # Save the processed DataFrame to a new CSV file\n        output_file = re.search(\"(\\d+)\", filename).group(0) + \"_onset_condensed.csv\"\n        df.to_csv(output_file, index=False)\n\n        if num % 100 == 0:\n            print(f\"Processed {filename} and saved to {output_file}\")","metadata":{"execution":{"iopub.status.busy":"2025-02-20T11:07:13.600457Z","iopub.execute_input":"2025-02-20T11:07:13.601243Z","iopub.status.idle":"2025-02-20T11:12:41.966853Z","shell.execute_reply.started":"2025-02-20T11:07:13.601209Z","shell.execute_reply":"2025-02-20T11:12:41.96575Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Processed 0521_onsets.arff and saved to 0521_onset_condensed.csv\nProcessed 2699_onsets.arff and saved to 2699_onset_condensed.csv\nProcessed 2634_onsets.arff and saved to 2634_onset_condensed.csv\nProcessed 0544_onsets.arff and saved to 0544_onset_condensed.csv\nProcessed 1658_onsets.arff and saved to 1658_onset_condensed.csv\nProcessed 1624_onsets.arff and saved to 1624_onset_condensed.csv\nProcessed 1192_onsets.arff and saved to 1192_onset_condensed.csv\nProcessed 0001_onsets.arff and saved to 0001_onset_condensed.csv\nProcessed 0382_onsets.arff and saved to 0382_onset_condensed.csv\nProcessed 1000_onsets.arff and saved to 1000_onset_condensed.csv\nProcessed 0541_onsets.arff and saved to 0541_onset_condensed.csv\nProcessed 1630_onsets.arff and saved to 1630_onset_condensed.csv\nProcessed 0696_onsets.arff and saved to 0696_onset_condensed.csv\nProcessed 0121_onsets.arff and saved to 0121_onset_condensed.csv\nProcessed 0097_onsets.arff and saved to 0097_onset_condensed.csv\nProcessed 0220_onsets.arff and saved to 0220_onset_condensed.csv\nProcessed 1161_onsets.arff and saved to 1161_onset_condensed.csv\nProcessed 2537_onsets.arff and saved to 2537_onset_condensed.csv\nProcessed 1108_onsets.arff and saved to 1108_onset_condensed.csv\nProcessed 0558_onsets.arff and saved to 0558_onset_condensed.csv\nProcessed 0564_onsets.arff and saved to 0564_onset_condensed.csv\nProcessed 2885_onsets.arff and saved to 2885_onset_condensed.csv\nProcessed 0646_onsets.arff and saved to 0646_onset_condensed.csv\nProcessed 2182_onsets.arff and saved to 2182_onset_condensed.csv\nProcessed 1541_onsets.arff and saved to 1541_onset_condensed.csv\nProcessed 1601_onsets.arff and saved to 1601_onset_condensed.csv\nProcessed 0352_onsets.arff and saved to 0352_onset_condensed.csv\nProcessed 1210_onsets.arff and saved to 1210_onset_condensed.csv\nProcessed 1189_onsets.arff and saved to 1189_onset_condensed.csv\nProcessed 2995_onsets.arff and saved to 2995_onset_condensed.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# 2: encode chord names and replace said chord names with encodings in beatinfo files\n\n# Directory path to your annotations folder\nheaders = ['Start time in seconds', 'Bar count', 'Quarter count', 'Chord name']\n\nchord_encodings = {0: 'A#maj', 1: 'A#min', 2: 'Amaj', 3: 'Amin', 4: 'Bmaj', 5: 'Bmin', 6: 'C#maj', 7: 'C#min', \n                   8: 'Cmaj', 9: 'Cmin', 10: 'D#maj', 11: 'D#min', 12: 'Dmaj', 13: 'Dmin', 14: 'Emaj', 15: 'Emin', \n                   16: 'F#maj', 17: 'F#min', 18: 'Fmaj', 19: 'Fmin', 20: 'G#maj', 21: 'G#min', 22: 'Gmaj', \n                   23: 'Gmin', 24: 'N.C.'}\n\ninverted_encodings = {'A#maj': 0, 'A#min': 1, 'Amaj': 2, 'Amin': 3, 'Bmaj': 4, 'Bmin': 5, 'C#maj': 6, 'C#min': 7, \n                   'Cmaj': 8, 'Cmin': 9, 'D#maj': 10, 'D#min': 11, 'Dmaj': 12, 'Dmin': 13, 'Emaj': 14, 'Emin': 15, \n                   'F#maj': 16, 'F#min': 17, 'Fmaj': 18, 'Fmin': 19, 'G#maj': 20, 'G#min': 21, 'Gmaj': 22, \n                   'Gmin': 23, 'N.C.': 24}\n\ndataframes = []\nfilenames = []\n\n# Iterate through all files in the directory\nfor filename in os.listdir(annotations_dir):\n    if \"beatinfo\" in filename and filename.endswith(\".arff\"):  # Ensure it's an ARFF file with 'beatinfo' in its name\n        file_path = os.path.join(annotations_dir, filename)\n        filenames.append(filename)\n        df = pd.read_csv(file_path, comment='@', header=None)\n        df.columns = headers\n\n        for i in range(df.index.size):\n            df.iat[i, 3] = df.iat[i, 3].replace(\"'\", \"\")\n            if df.iat[i, 3] == \"BASS_NOTE_EXCEPTION\":\n                df.iat[i, 3] = \"N.C.\"\n            df.iat[i, 3] = inverted_encodings[df.iat[i, 3]]\n    \n        df.to_csv(filename.replace('arff', 'csv'), index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T11:12:55.013647Z","iopub.execute_input":"2025-02-20T11:12:55.014011Z","iopub.status.idle":"2025-02-20T11:14:26.414956Z","shell.execute_reply.started":"2025-02-20T11:12:55.013979Z","shell.execute_reply":"2025-02-20T11:14:26.413639Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# visualize the files\nworking_dir = \"/kaggle/working/\"\nonsets = pd.read_csv(working_dir + \"0001_onset_condensed.csv\")\nprint(onsets.head())\nbeatinfo = pd.read_csv(working_dir + \"0001_beatinfo.csv\")\nprint(beatinfo.head())\n\ndef align_onsets_with_chords(onsets, beatinfo):\n    aligned_data = []\n    for _, onset_row in onsets.iterrows():\n        onset_time = onset_row['Onset time in seconds']\n        # Find the chord corresponding to this onset time\n        chord_row = beatinfo[beatinfo['Start time in seconds'] <= onset_time].iloc[-1]\n        onset_list = eval(onset_row['Onset events'])\n        aligned_data.append((onset_list, chord_row['Chord name']))\n    return aligned_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T11:15:02.327626Z","iopub.execute_input":"2025-02-20T11:15:02.327952Z","iopub.status.idle":"2025-02-20T11:15:02.347912Z","shell.execute_reply.started":"2025-02-20T11:15:02.327928Z","shell.execute_reply":"2025-02-20T11:15:02.346615Z"}},"outputs":[{"name":"stdout","text":"   Onset time in seconds  Onset events\n0               0.000000  [41, 60, 65]\n1               0.326086      [41, 60]\n2               0.652173  [41, 65, 65]\n3               0.978259  [41, 65, 69]\n4               1.304346  [41, 65, 65]\n   Start time in seconds  Bar count  Quarter count  Chord name\n0               0.000000          1              1          18\n1               0.652174          1              2          18\n2               1.304348          1              3          18\n3               1.956522          1              4          18\n4               2.608696          2              1           0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# create aligned data for every onset and beatinfo file\n\nall_data = []\n\nfor filename in os.listdir(working_dir):\n    if \"onset\" in filename:\n        onset_path = os.path.join(working_dir, filename)\n        beatinfo_path = os.path.join(working_dir, re.search(\"(\\d+)\", filename).group(0) + \"_beatinfo.csv\")\n        onsets = pd.read_csv(onset_path)\n        beatinfo = pd.read_csv(beatinfo_path)\n        all_data.append(align_onsets_with_chords(onsets, beatinfo))\n\nprint(len(all_data))\n#print(all_data[0:20])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T11:50:54.820066Z","iopub.execute_input":"2025-02-20T11:50:54.820478Z","iopub.status.idle":"2025-02-20T12:06:12.291934Z","shell.execute_reply.started":"2025-02-20T11:50:54.820449Z","shell.execute_reply":"2025-02-20T12:06:12.290715Z"}},"outputs":[{"name":"stdout","text":"3000\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Embedding, LSTM, Dense, TimeDistributed, BatchNormalization\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\n\ndef create_chord_classification_model(vocab_size, embedding_dim, lstm_units, num_classes, max_sequence_length):\n    # Input for note sequences\n    note_input = Input(shape=(max_sequence_length,))\n    \n    # Embedding layer for note sequences\n    note_embedding = Embedding(vocab_size, embedding_dim)(note_input)\n    \n    # LSTM layers\n    lstm_output = LSTM(lstm_units, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(note_embedding) # with more lstm layers, return sequences = true\n    lstm_output = BatchNormalization()(lstm_output)\n    lstm_output = LSTM(lstm_units, return_sequences=False, dropout=0.2, recurrent_dropout=0.2)(lstm_output)\n    \n    # Output layer\n    output = Dense(num_classes, activation='softmax', kernel_regularizer=l2(0.01))(lstm_output)\n    \n    model = Model(inputs=note_input, outputs=output)\n    return model\n\n# Hyperparameters\nvocab_size = 128  # Assuming MIDI note range\nembedding_dim = 32\nlstm_units = 64\nnum_classes = 25  # Number of chord classes\nmax_sequence_length = 16  # Adjust based on your data\n\n# Create the model\nmodel = create_chord_classification_model(vocab_size, embedding_dim, lstm_units, num_classes, max_sequence_length)\n\n# Compile the model\noptimizer = Adam(learning_rate=0.0001)\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Split at the song level (here I can decide how many of the songs I want to use)\ntrain_songs, test_songs = train_test_split(all_data[0:40], test_size=0.2, random_state=42)\n\n# Flatten sequences within each split\ntrain_data = [pair for song in train_songs for pair in song]  # Keep full song sequences together\ntest_data = [pair for song in test_songs for pair in song]\n\nprint(f\"Total training sequences: {len(train_data)}\")\nprint(f\"Total testing sequences: {len(test_data)}\")\n\n# Function to prepare data\ndef prepare_data(data, max_sequence_length):\n    X, y = [], []\n    for notes, chord in data:\n        padded_notes = tf.keras.preprocessing.sequence.pad_sequences([notes], maxlen=max_sequence_length, padding='post', truncating='post')[0]\n        X.append(padded_notes)\n        y.append(chord)\n    return np.array(X), np.array(y)\n\n# Prepare train and test data\nX_train, y_train = prepare_data(train_data, max_sequence_length)\nX_test, y_test = prepare_data(test_data, max_sequence_length)\n\n# Convert y to one-hot encoding\ny_train_onehot = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\ny_test_onehot = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)\n\n# Train the model\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\nhistory = model.fit(X_train, y_train_onehot, validation_data=(X_test, y_test_onehot), epochs=100, batch_size=32, callbacks=[early_stopping])\n\n# Function for inference\ndef predict_chord(model, note_sequence):\n    padded_sequence = tf.keras.preprocessing.sequence.pad_sequences([note_sequence], maxlen=max_sequence_length, padding='post', truncating='post')\n    predictions = model.predict(padded_sequence)\n    return np.argmax(predictions[0])  # Return the prediction\n\n# Example usage\nsample_sequence = [60, 64, 67, 72]  # C major chor\npredicted_chord = predict_chord(model, sample_sequence)\nprint(f\"Predicted chord num: {predicted_chord}\")\nprint(f\"Predicted chord: {chord_encodings[predicted_chord]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T12:07:56.808612Z","iopub.execute_input":"2025-02-20T12:07:56.80902Z","iopub.status.idle":"2025-02-20T12:17:02.340994Z","shell.execute_reply.started":"2025-02-20T12:07:56.808988Z","shell.execute_reply":"2025-02-20T12:17:02.339679Z"}},"outputs":[{"name":"stdout","text":"Total training sequences: 16925\nTotal testing sequences: 4307\nEpoch 1/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - accuracy: 0.0985 - loss: 3.4378 - val_accuracy: 0.2635 - val_loss: 2.7699\nEpoch 2/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.4189 - loss: 2.3574 - val_accuracy: 0.6164 - val_loss: 1.7972\nEpoch 3/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.5785 - loss: 1.8745 - val_accuracy: 0.7035 - val_loss: 1.5333\nEpoch 4/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 20ms/step - accuracy: 0.6422 - loss: 1.6700 - val_accuracy: 0.7562 - val_loss: 1.4032\nEpoch 5/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.6817 - loss: 1.5760 - val_accuracy: 0.7848 - val_loss: 1.2930\nEpoch 6/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.7044 - loss: 1.4758 - val_accuracy: 0.7896 - val_loss: 1.2402\nEpoch 7/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.7154 - loss: 1.4397 - val_accuracy: 0.7980 - val_loss: 1.1925\nEpoch 8/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.7298 - loss: 1.3709 - val_accuracy: 0.8052 - val_loss: 1.1690\nEpoch 9/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.7404 - loss: 1.3377 - val_accuracy: 0.8073 - val_loss: 1.1337\nEpoch 10/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.7466 - loss: 1.3118 - val_accuracy: 0.8057 - val_loss: 1.1160\nEpoch 11/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.7466 - loss: 1.2949 - val_accuracy: 0.8103 - val_loss: 1.0917\nEpoch 12/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.7558 - loss: 1.2611 - val_accuracy: 0.8105 - val_loss: 1.0807\nEpoch 13/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.7596 - loss: 1.2540 - val_accuracy: 0.8105 - val_loss: 1.0785\nEpoch 14/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.7689 - loss: 1.2186 - val_accuracy: 0.8136 - val_loss: 1.0696\nEpoch 15/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 28ms/step - accuracy: 0.7691 - loss: 1.2054 - val_accuracy: 0.8124 - val_loss: 1.0588\nEpoch 16/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 28ms/step - accuracy: 0.7650 - loss: 1.2015 - val_accuracy: 0.8187 - val_loss: 1.0529\nEpoch 17/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 29ms/step - accuracy: 0.7738 - loss: 1.1858 - val_accuracy: 0.8112 - val_loss: 1.0523\nEpoch 18/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 31ms/step - accuracy: 0.7794 - loss: 1.1618 - val_accuracy: 0.8126 - val_loss: 1.0410\nEpoch 19/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 29ms/step - accuracy: 0.7838 - loss: 1.1460 - val_accuracy: 0.8205 - val_loss: 1.0326\nEpoch 20/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 31ms/step - accuracy: 0.7815 - loss: 1.1507 - val_accuracy: 0.8201 - val_loss: 1.0255\nEpoch 21/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - accuracy: 0.7855 - loss: 1.1332 - val_accuracy: 0.8231 - val_loss: 1.0241\nEpoch 22/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 28ms/step - accuracy: 0.7887 - loss: 1.1229 - val_accuracy: 0.8231 - val_loss: 1.0191\nEpoch 23/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.7879 - loss: 1.1183 - val_accuracy: 0.8293 - val_loss: 1.0021\nEpoch 24/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.7849 - loss: 1.1179 - val_accuracy: 0.8263 - val_loss: 1.0009\nEpoch 25/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.7947 - loss: 1.0953 - val_accuracy: 0.8263 - val_loss: 0.9960\nEpoch 26/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.7964 - loss: 1.0907 - val_accuracy: 0.8147 - val_loss: 0.9990\nEpoch 27/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7903 - loss: 1.0995 - val_accuracy: 0.8270 - val_loss: 0.9952\nEpoch 28/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.7929 - loss: 1.0873 - val_accuracy: 0.8275 - val_loss: 0.9892\nEpoch 29/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.7964 - loss: 1.0792 - val_accuracy: 0.8091 - val_loss: 0.9967\nEpoch 30/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.7909 - loss: 1.0928 - val_accuracy: 0.8275 - val_loss: 0.9835\nEpoch 31/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.8002 - loss: 1.0600 - val_accuracy: 0.8282 - val_loss: 1.0000\nEpoch 32/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.8012 - loss: 1.0502 - val_accuracy: 0.8182 - val_loss: 0.9939\nEpoch 33/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.7994 - loss: 1.0526 - val_accuracy: 0.8219 - val_loss: 0.9910\nEpoch 34/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.7994 - loss: 1.0501 - val_accuracy: 0.8173 - val_loss: 0.9938\nEpoch 35/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.8064 - loss: 1.0299 - val_accuracy: 0.8242 - val_loss: 0.9809\nEpoch 36/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.8029 - loss: 1.0450 - val_accuracy: 0.8235 - val_loss: 0.9879\nEpoch 37/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.8046 - loss: 1.0414 - val_accuracy: 0.8226 - val_loss: 0.9900\nEpoch 38/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.8163 - loss: 0.9970 - val_accuracy: 0.8256 - val_loss: 0.9843\nEpoch 39/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.8105 - loss: 1.0284 - val_accuracy: 0.8194 - val_loss: 0.9836\nEpoch 40/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.8036 - loss: 1.0368 - val_accuracy: 0.8305 - val_loss: 0.9693\nEpoch 41/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.8122 - loss: 1.0063 - val_accuracy: 0.8305 - val_loss: 0.9759\nEpoch 42/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.8109 - loss: 1.0172 - val_accuracy: 0.8238 - val_loss: 0.9858\nEpoch 43/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.8142 - loss: 1.0097 - val_accuracy: 0.8205 - val_loss: 0.9829\nEpoch 44/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.8059 - loss: 1.0294 - val_accuracy: 0.8284 - val_loss: 0.9801\nEpoch 45/100\n\u001b[1m529/529\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 20ms/step - accuracy: 0.8099 - loss: 1.0134 - val_accuracy: 0.8268 - val_loss: 0.9828\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step\nPredicted chord num: 8\nPredicted chord: Cmaj\n","output_type":"stream"}],"execution_count":12}]}