{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sharabhojha/modified-chord-generation-lstm?scriptVersionId=234014082\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"ebebf97a","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-04-15T09:19:17.486846Z","iopub.status.busy":"2025-04-15T09:19:17.486541Z","iopub.status.idle":"2025-04-15T09:19:18.240029Z","shell.execute_reply":"2025-04-15T09:19:18.239314Z"},"papermill":{"duration":0.759438,"end_time":"2025-04-15T09:19:18.241732","exception":false,"start_time":"2025-04-15T09:19:17.482294","status":"completed"},"tags":[]},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","import re\n","import pandas as pd\n","###!pip install liac-arff\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"id":"77acc06c","metadata":{"execution":{"iopub.execute_input":"2025-04-15T09:19:18.248264Z","iopub.status.busy":"2025-04-15T09:19:18.247907Z","iopub.status.idle":"2025-04-15T09:19:18.253539Z","shell.execute_reply":"2025-04-15T09:19:18.252782Z"},"papermill":{"duration":0.009971,"end_time":"2025-04-15T09:19:18.254802","exception":false,"start_time":"2025-04-15T09:19:18.244831","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'\\nimport re\\nimport pandas as pd\\nimport arff\\n\\n# Directory path to your annotations folder\\nannotations_dir = \"/kaggle/input/aam-annotations/AAM-annotations/\"\\nnum = 0\\n\\n# Iterate through all files in the directory\\nfor filename in os.listdir(annotations_dir):\\n    if \"onsets\" in filename and filename.endswith(\".arff\"):  # Ensure it\\'s an ARFF file with \\'onsets\\' in its name\\n        num += 1\\n        file_path = os.path.join(annotations_dir, filename)\\n        \\n        # Read the ARFF file\\n        def read_arff(file_path):\\n            with open(file_path, \\'r\\') as f:\\n                arff_data = arff.load(f)\\n            return pd.DataFrame(arff_data[\\'data\\'], columns=[attr[0] for attr in arff_data[\\'attributes\\']])\\n        \\n        # Use this function instead of manual parsing\\n        df = read_arff(file_path)\\n\\n        # Convert numeric columns where possible\\n        for col in df.columns:\\n            try:\\n                df[col] = pd.to_numeric(df[col])  # Convert if possible\\n            except ValueError:\\n                pass  # Keep as string if conversion fails\\n\\n        all_onsets = []\\n\\n        # Vectorized operation to collect all onset events\\n        df.drop(columns=[\"Onset events of Drums\"], inplace=True)\\n        onset_columns = df.columns[df.apply(lambda col: col.astype(str).str.contains(r\"\\\\[\", regex=True)).any()]\\n        df[\"Onset events\"] = df[onset_columns].apply(lambda row: [int(x) for x in re.findall(r\\'\\\\d+\\', \\'\\'.join(row.astype(str)))], axis=1)\\n        df.drop(onset_columns, axis=1, inplace=True)\\n\\n        # Save the processed DataFrame to a new CSV file\\n        output_file = re.search(\"(\\\\d+)\", filename).group(0) + \"_onset_condensed.csv\"\\n        df.to_csv(output_file, index=False)\\n\\n        if num % 100 == 0:\\n            print(f\"Processed {filename} and saved to {output_file}\")'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Preprocessing steps:\n","# 1: condense onset files to just onset times and onset notes\n","\"\"\"\n","import re\n","import pandas as pd\n","import arff\n","\n","# Directory path to your annotations folder\n","annotations_dir = \"/kaggle/input/aam-annotations/AAM-annotations/\"\n","num = 0\n","\n","# Iterate through all files in the directory\n","for filename in os.listdir(annotations_dir):\n","    if \"onsets\" in filename and filename.endswith(\".arff\"):  # Ensure it's an ARFF file with 'onsets' in its name\n","        num += 1\n","        file_path = os.path.join(annotations_dir, filename)\n","        \n","        # Read the ARFF file\n","        def read_arff(file_path):\n","            with open(file_path, 'r') as f:\n","                arff_data = arff.load(f)\n","            return pd.DataFrame(arff_data['data'], columns=[attr[0] for attr in arff_data['attributes']])\n","        \n","        # Use this function instead of manual parsing\n","        df = read_arff(file_path)\n","\n","        # Convert numeric columns where possible\n","        for col in df.columns:\n","            try:\n","                df[col] = pd.to_numeric(df[col])  # Convert if possible\n","            except ValueError:\n","                pass  # Keep as string if conversion fails\n","\n","        all_onsets = []\n","\n","        # Vectorized operation to collect all onset events\n","        df.drop(columns=[\"Onset events of Drums\"], inplace=True)\n","        onset_columns = df.columns[df.apply(lambda col: col.astype(str).str.contains(r\"\\[\", regex=True)).any()]\n","        df[\"Onset events\"] = df[onset_columns].apply(lambda row: [int(x) for x in re.findall(r'\\d+', ''.join(row.astype(str)))], axis=1)\n","        df.drop(onset_columns, axis=1, inplace=True)\n","\n","        # Save the processed DataFrame to a new CSV file\n","        output_file = re.search(\"(\\d+)\", filename).group(0) + \"_onset_condensed.csv\"\n","        df.to_csv(output_file, index=False)\n","\n","        if num % 100 == 0:\n","            print(f\"Processed {filename} and saved to {output_file}\")\"\"\""]},{"cell_type":"code","execution_count":3,"id":"a654b2f0","metadata":{"execution":{"iopub.execute_input":"2025-04-15T09:19:18.260454Z","iopub.status.busy":"2025-04-15T09:19:18.260254Z","iopub.status.idle":"2025-04-15T09:19:18.271901Z","shell.execute_reply":"2025-04-15T09:19:18.271054Z"},"papermill":{"duration":0.016212,"end_time":"2025-04-15T09:19:18.273548","exception":false,"start_time":"2025-04-15T09:19:18.257336","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["{0: [70, 74, 77, 82], 1: [70, 73, 77, 82], 2: [69, 73, 76, 81], 3: [69, 72, 76, 81], 4: [71, 75, 78, 83], 5: [71, 74, 78, 83], 6: [61, 65, 68, 73], 7: [61, 64, 68, 73], 8: [60, 64, 67, 72], 9: [60, 63, 67, 72], 10: [63, 67, 70, 75], 11: [63, 66, 70, 75], 12: [62, 66, 69, 74], 13: [62, 65, 69, 74], 14: [64, 68, 71, 76], 15: [64, 67, 71, 76], 16: [66, 70, 73, 78], 17: [66, 69, 73, 78], 18: [65, 69, 72, 77], 19: [65, 68, 72, 77], 20: [68, 72, 75, 80], 21: [68, 71, 75, 80], 22: [67, 71, 74, 79], 23: [67, 70, 74, 79]}\n"]},{"data":{"text/plain":["'\\n# Directory path to your annotations folder\\nheaders = [\\'Start time in seconds\\', \\'Bar count\\', \\'Quarter count\\', \\'Chord name\\']\\n\\n# Iterate through all files in the directory\\nfor filename in os.listdir(annotations_dir):\\n    if \"beatinfo\" in filename and filename.endswith(\".arff\"):  # Ensure it\\'s an ARFF file with \\'beatinfo\\' in its name\\n        file_path = os.path.join(annotations_dir, filename)\\n        df = pd.read_csv(file_path, comment=\\'@\\', header=None)\\n        df.columns = headers\\n\\n        for i in range(df.index.size):\\n            df.iat[i, 3] = df.iat[i, 3].replace(\"\\'\", \"\")\\n            if df.iat[i, 3] == \"BASS_NOTE_EXCEPTION\":\\n                df.iat[i, 3] = \"N.C.\"\\n            df.iat[i, 3] = inverted_encodings[df.iat[i, 3]]\\n    \\n        df.to_csv(filename.replace(\\'arff\\', \\'csv\\'), index=False)'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# 2: encode chord names and replace said chord names with encodings in beatinfo files\n","\n","chord_encodings = {0: 'A#maj', 1: 'A#min', 2: 'Amaj', 3: 'Amin', 4: 'Bmaj', 5: 'Bmin', 6: 'C#maj', 7: 'C#min', \n","                   8: 'Cmaj', 9: 'Cmin', 10: 'D#maj', 11: 'D#min', 12: 'Dmaj', 13: 'Dmin', 14: 'Emaj', 15: 'Emin', \n","                   16: 'F#maj', 17: 'F#min', 18: 'Fmaj', 19: 'Fmin', 20: 'G#maj', 21: 'G#min', 22: 'Gmaj', \n","                   23: 'Gmin', 24: 'N.C.'}\n","\n","inverted_encodings = dict(zip(chord_encodings.values(), chord_encodings.keys()))\n","\n","chords = {\"Cmaj\": [60, 64, 67, 72], \"Cmin\": [60, 63, 67, 72], \"C#maj\": [61, 65, 68, 73], \"C#min\": [61, 64, 68, 73],\n","          \"Dmaj\": [62, 66, 69, 74], \"Dmin\": [62, 65, 69, 74], \"D#maj\": [63, 67, 70, 75], \"D#min\": [63, 66, 70, 75],\n","          \"Emaj\": [64, 68, 71, 76], \"Emin\": [64, 67, 71, 76], \"Fmaj\": [65, 69, 72, 77], \"Fmin\": [65, 68, 72, 77],\n","          \"F#maj\": [66, 70, 73, 78], \"F#min\": [66, 69, 73, 78], \"Gmaj\": [67, 71, 74, 79], \"Gmin\": [67, 70, 74, 79],\n","          \"G#maj\": [68, 72, 75, 80], \"G#min\": [68, 71, 75, 80], \"Amaj\": [69, 73, 76, 81], \"Amin\": [69, 72, 76, 81],\n","          \"A#maj\": [70, 74, 77, 82], \"A#min\": [70, 73, 77, 82], \"Bmaj\": [71, 75, 78, 83], \"Bmin\": [71, 74, 78, 83]}\n","\n","midi_chord_dict = {}\n","\n","for label, chord_name in chord_encodings.items():\n","    midi_chord_dict[label] = chords.get(chord_name, [])\n","\n","midi_chord_dict.pop(24)\n","\n","print(midi_chord_dict)\n","\n","\"\"\"\n","# Directory path to your annotations folder\n","headers = ['Start time in seconds', 'Bar count', 'Quarter count', 'Chord name']\n","\n","# Iterate through all files in the directory\n","for filename in os.listdir(annotations_dir):\n","    if \"beatinfo\" in filename and filename.endswith(\".arff\"):  # Ensure it's an ARFF file with 'beatinfo' in its name\n","        file_path = os.path.join(annotations_dir, filename)\n","        df = pd.read_csv(file_path, comment='@', header=None)\n","        df.columns = headers\n","\n","        for i in range(df.index.size):\n","            df.iat[i, 3] = df.iat[i, 3].replace(\"'\", \"\")\n","            if df.iat[i, 3] == \"BASS_NOTE_EXCEPTION\":\n","                df.iat[i, 3] = \"N.C.\"\n","            df.iat[i, 3] = inverted_encodings[df.iat[i, 3]]\n","    \n","        df.to_csv(filename.replace('arff', 'csv'), index=False)\"\"\""]},{"cell_type":"code","execution_count":4,"id":"f117fffd","metadata":{"execution":{"iopub.execute_input":"2025-04-15T09:19:18.279683Z","iopub.status.busy":"2025-04-15T09:19:18.27948Z","iopub.status.idle":"2025-04-15T09:19:18.328614Z","shell.execute_reply":"2025-04-15T09:19:18.327586Z"},"papermill":{"duration":0.0536,"end_time":"2025-04-15T09:19:18.329958","exception":false,"start_time":"2025-04-15T09:19:18.276358","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["   Onset time in seconds  Onset events\n","0               0.000000  [41, 60, 65]\n","1               0.326086      [41, 60]\n","2               0.652173  [41, 65, 65]\n","3               0.978259  [41, 65, 69]\n","4               1.304346  [41, 65, 65]\n","   Start time in seconds  Bar count  Quarter count  Chord name\n","0               0.000000          1              1          18\n","1               0.652174          1              2          18\n","2               1.304348          1              3          18\n","3               1.956522          1              4          18\n","4               2.608696          2              1           0\n"]}],"source":["# visualize the files\n","\n","###working_dir = \"/kaggle/working/\"\n","working_dir = \"/kaggle/input/aam-paired-chord-onset-dataset/\"\n","onsets = pd.read_csv(working_dir + \"0001_onset_condensed.csv\")\n","print(onsets.head())\n","beatinfo = pd.read_csv(working_dir + \"0001_beatinfo.csv\")\n","print(beatinfo.head())\n","\n","def align_onsets_with_chords(onsets, beatinfo):\n","    aligned_data = []\n","    for _, onset_row in onsets.iterrows():\n","        onset_time = onset_row['Onset time in seconds']\n","        # Find the chord corresponding to this onset time\n","        chord_row = beatinfo[beatinfo['Start time in seconds'] <= onset_time].iloc[-1]\n","        onset_list = eval(onset_row['Onset events'])\n","        if chord_row['Chord name'] != 24 and len(onset_list) > 0:\n","            if len(aligned_data) > 0:\n","                aligned_data.append((onset_list, aligned_data[-1][2], int(chord_row['Chord name'])))\n","                continue\n","            # replace second param with int(chord_row['Chord name'])\n","            aligned_data.append((onset_list, 24, int(chord_row['Chord name'])))\n","    return aligned_data"]},{"cell_type":"code","execution_count":5,"id":"b0a7fd9f","metadata":{"execution":{"iopub.execute_input":"2025-04-15T09:19:18.336342Z","iopub.status.busy":"2025-04-15T09:19:18.336094Z","iopub.status.idle":"2025-04-15T09:23:35.468391Z","shell.execute_reply":"2025-04-15T09:23:35.467548Z"},"papermill":{"duration":257.137429,"end_time":"2025-04-15T09:23:35.470315","exception":false,"start_time":"2025-04-15T09:19:18.332886","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["50\n","100\n","150\n","200\n","250\n","300\n","350\n","400\n","450\n","500\n","550\n","600\n","650\n","700\n","750\n","800\n","850\n","900\n","950\n","1000\n","[[([41, 60, 65], 24, 18), ([41, 60], 18, 18), ([41, 65, 65], 18, 18), ([41, 65, 69], 18, 18), ([41, 65, 65], 18, 18), ([41, 65, 69], 18, 18), ([41, 64, 60], 18, 18), ([41, 64, 65], 18, 18), ([46, 67, 70], 18, 18), ([46, 67, 65], 18, 0), ([46, 67, 70], 0, 0), ([46, 69, 62], 0, 0), ([46, 60, 70], 0, 0), ([46, 62], 0, 0), ([46, 65, 65], 0, 0), ([46, 65, 70], 0, 0), ([45, 69, 69], 0, 0), ([45, 64, 64], 0, 3), ([45, 65, 69], 3, 3), ([45, 69, 60], 3, 3), ([38, 69, 62], 3, 3), ([38, 65, 69], 3, 13), ([38, 60, 62], 13, 13), ([38, 65], 13, 13), ([38, 60, 62], 13, 13), ([38, 60, 69], 13, 13), ([38, 65, 62], 13, 13), ([38, 65, 65], 13, 13), ([38, 65, 62], 13, 13), ([38, 65, 65], 13, 13), ([38, 64, 69], 13, 13), ([38, 62], 13, 13), ([36, 67, 60], 13, 13), ([36, 67], 13, 8), ([36, 67, 60], 8, 8), ([36, 69, 64], 8, 8), ([36, 69, 60], 8, 8), ([36, 65, 64], 8, 8), ([36, 62, 67], 8, 8), ([36, 62, 60], 8, 8), ([41, 65, 65], 8, 8), ([41, 65, 60], 8, 18), ([41, 65, 65], 18, 18), ([41, 65, 69], 18, 18), ([41, 65], 18, 18), ([41, 69], 18, 18), ([41, 60], 18, 18), ([41, 65], 18, 18), ([41, 60, 65], 18, 18), ([41, 60], 18, 18), ([41, 65, 65], 18, 18), ([41, 65, 69], 18, 18), ([41, 65, 65], 18, 18), ([41, 65, 69], 18, 18), ([41, 64, 60], 18, 18), ([41, 64, 65], 18, 18), ([46, 67, 70], 18, 18), ([46, 67, 65], 18, 0), ([46, 67, 70], 0, 0), ([46, 69, 62], 0, 0), ([46, 60, 70], 0, 0), ([46, 62], 0, 0), ([46, 65, 65], 0, 0), ([46, 65, 70], 0, 0), ([45, 69, 69], 0, 0), ([45, 64, 64], 0, 3), ([45, 65, 69], 3, 3), ([45, 69, 60], 3, 3), ([38, 69, 62], 3, 3), ([38, 65, 69], 3, 13), ([38, 60, 62], 13, 13), ([38, 65], 13, 13), ([38, 60, 62], 13, 13), ([38, 60, 69], 13, 13), ([38, 65, 62], 13, 13), ([38, 65, 65], 13, 13), ([38, 65, 62], 13, 13), ([38, 65, 65], 13, 13), ([38, 64, 69], 13, 13), ([38, 62], 13, 13), ([36, 67, 60], 13, 13), ([36, 67], 13, 8), ([36, 67, 60], 8, 8), ([36, 69, 64], 8, 8), ([36, 69, 60], 8, 8), ([36, 65, 64], 8, 8), ([36, 62, 67], 8, 8), ([36, 62, 60], 8, 8), ([41, 65, 65], 8, 8), ([41, 65, 60], 8, 18), ([41, 65, 65], 18, 18), ([41, 65, 69], 18, 18), ([41, 65], 18, 18), ([41, 69], 18, 18), ([41, 60], 18, 18), ([41, 65], 18, 18), ([41, 60, 65], 18, 18), ([41, 60], 18, 18), ([41, 65, 65], 18, 18), ([41, 65, 69], 18, 18), ([41, 65, 65], 18, 18), ([41, 65, 69], 18, 18), ([41, 64, 60], 18, 18), ([41, 64, 65], 18, 18), ([46, 67, 70], 18, 18), ([46, 67, 65], 18, 0), ([46, 67, 70], 0, 0), ([46, 69, 62], 0, 0), ([46, 60, 70], 0, 0), ([46, 62], 0, 0), ([46, 65, 65], 0, 0), ([46, 65, 70], 0, 0), ([45, 69, 69], 0, 0), ([45, 64, 64], 0, 3), ([45, 65, 69], 3, 3), ([45, 69, 60], 3, 3), ([38, 69, 62], 3, 3), ([38, 65, 69], 3, 13), ([38, 60, 62], 13, 13), ([38, 65], 13, 13), ([38, 60, 62], 13, 13), ([38, 60, 69], 13, 13), ([38, 65, 62], 13, 13), ([38, 65, 65], 13, 13), ([38, 65, 62], 13, 13), ([38, 65, 65], 13, 13), ([38, 64, 69], 13, 13), ([38, 62], 13, 13), ([36, 67, 60], 13, 13), ([36, 67], 13, 8), ([36, 67, 60], 8, 8), ([36, 69, 64], 8, 8), ([36, 69, 60], 8, 8), ([36, 65, 64], 8, 8), ([36, 62, 67], 8, 8), ([36, 62, 60], 8, 8), ([41, 65, 65], 8, 8), ([41, 65, 60], 8, 18), ([41, 65, 65], 18, 18), ([41, 65, 69], 18, 18), ([41, 65], 18, 18), ([41, 69], 18, 18), ([41, 60], 18, 18), ([41, 65], 18, 18), ([41, 60, 65], 18, 18), ([41, 60], 18, 18), ([41, 65, 65], 18, 18), ([41, 65, 69], 18, 18), ([41, 65, 65], 18, 18), ([41, 65, 69], 18, 18), ([41, 64, 60], 18, 18), ([41, 64, 65], 18, 18), ([46, 67, 70], 18, 18), ([46, 67, 65], 18, 0), ([46, 67, 70], 0, 0), ([46, 69, 62], 0, 0), ([46, 60, 70], 0, 0), ([46, 62], 0, 0), ([46, 65, 65], 0, 0), ([46, 65, 70], 0, 0), ([45, 69, 69], 0, 0), ([45, 64, 64], 0, 3), ([45, 65, 69], 3, 3), ([45, 69, 60], 3, 3), ([38, 69, 62], 3, 3), ([38, 65, 69], 3, 13), ([38, 60, 62], 13, 13), ([38, 65], 13, 13), ([38, 60, 62], 13, 13), ([38, 60, 69], 13, 13), ([38, 65, 62], 13, 13), ([38, 65, 65], 13, 13), ([38, 65, 62], 13, 13), ([38, 65, 65], 13, 13), ([38, 64, 69], 13, 13), ([38, 62], 13, 13), ([36, 67, 60], 13, 13), ([36, 67], 13, 8), ([36, 67, 60], 8, 8), ([36, 69, 64], 8, 8), ([36, 69, 60], 8, 8), ([36, 65, 64], 8, 8), ([36, 62, 67], 8, 8), ([36, 62, 60], 8, 8), ([41, 65, 65], 8, 8), ([41, 65, 60], 8, 18), ([41, 65, 65], 18, 18), ([41, 65, 69], 18, 18), ([41, 65], 18, 18), ([41, 69], 18, 18), ([41, 60], 18, 18), ([41, 65], 18, 18), ([41, 60, 65], 18, 18), ([41, 60], 18, 18), ([41, 65, 65], 18, 18), ([41, 65, 69], 18, 18), ([41, 65, 65], 18, 18), ([41, 65, 69], 18, 18), ([41, 64, 60], 18, 18), ([41, 64, 65], 18, 18), ([46, 67, 70], 18, 18), ([46, 67, 65], 18, 0), ([46, 67, 70], 0, 0), ([46, 69, 62], 0, 0), ([46, 60, 70], 0, 0), ([46, 62], 0, 0), ([46, 65, 65], 0, 0), ([46, 65, 70], 0, 0), ([45, 69, 69], 0, 0), ([45, 64, 64], 0, 3), ([45, 65, 69], 3, 3), ([45, 69, 60], 3, 3), ([38, 69, 62], 3, 3), ([38, 65, 69], 3, 13), ([38, 60, 62], 13, 13), ([38, 65], 13, 13), ([38, 60, 62], 13, 13), ([38, 60, 69], 13, 13), ([38, 65, 62], 13, 13), ([38, 65, 65], 13, 13), ([38, 65, 62], 13, 13), ([38, 65, 65], 13, 13), ([38, 64, 69], 13, 13), ([38, 62], 13, 13), ([36, 67, 60], 13, 13), ([36, 67], 13, 8), ([36, 67, 60], 8, 8), ([36, 69, 64], 8, 8), ([36, 69, 60], 8, 8), ([36, 65, 64], 8, 8), ([36, 62, 67], 8, 8), ([36, 62, 60], 8, 8), ([41, 65, 65], 8, 8), ([41, 65, 60], 8, 18), ([41, 65, 65], 18, 18), ([41, 65, 69], 18, 18), ([41, 65], 18, 18), ([41, 69], 18, 18), ([41, 60], 18, 18), ([41, 65], 18, 18), ([43], 18, 18), ([69, 43], 18, 23), ([65, 43], 23, 23), ([65, 43], 23, 23), ([65, 43], 23, 23), ([43], 23, 23), ([63, 43], 23, 23), ([65, 43], 23, 23), ([69, 39], 23, 23), ([67, 39], 23, 10), ([67, 39], 10, 10), ([63, 39], 10, 10), ([63, 39], 10, 10), ([62, 39], 10, 10), ([39], 10, 10), ([67, 39], 10, 10), ([65, 38], 10, 10), ([65, 38], 10, 13), ([70, 38], 13, 13), ([70, 38], 13, 13), ([67, 38], 13, 13), ([38], 13, 13), ([67, 38], 13, 13), ([38], 13, 13), ([70, 46], 13, 13), ([63, 46], 13, 0), ([62, 46], 0, 0), ([62, 46], 0, 0), ([67, 46], 0, 0), ([63, 46], 0, 0), ([46], 0, 0), ([65, 46], 0, 0), ([43], 0, 0), ([69, 43], 0, 23), ([65, 43], 23, 23), ([65, 43], 23, 23), ([65, 43], 23, 23), ([65, 43], 23, 23), ([63, 43], 23, 23), ([65, 43], 23, 23), ([69, 39], 23, 23), ([67, 39], 23, 10), ([67, 39], 10, 10), ([63, 39], 10, 10), ([63, 41], 10, 10), ([62, 41], 10, 18), ([41], 18, 18), ([41], 18, 18), ([43], 18, 18), ([67, 43], 18, 23), ([43], 23, 23), ([65, 43], 23, 23), ([70, 43], 23, 23), ([67, 43], 23, 23), ([70, 43], 23, 23), ([70, 43], 23, 23), ([69, 41], 23, 23), ([69, 41], 23, 18), ([41], 18, 18), ([69, 41], 18, 18), ([67, 41], 18, 18), ([67, 41], 18, 18), ([63, 41], 18, 18), ([41], 18, 18), ([43], 18, 18), ([69, 43], 18, 23), ([65, 43], 23, 23), ([65, 43], 23, 23), ([65, 43], 23, 23), ([65, 43], 23, 23), ([63, 43], 23, 23), ([65, 43], 23, 23), ([69, 43], 23, 23), ([67, 43], 23, 23), ([67, 43], 23, 23), ([63, 43], 23, 23), ([63, 43], 23, 23), ([62, 43], 23, 23), ([43], 23, 23), ([67, 43], 23, 23), ([65, 38], 23, 23), ([65, 38], 23, 13), ([70, 38], 13, 13), ([38], 13, 13), ([67, 38], 13, 13), ([67, 38], 13, 13), ([67, 38], 13, 13), ([67, 38], 13, 13), ([65, 39], 13, 13), ([69, 39], 13, 10), ([63, 39], 10, 10), ([39], 10, 10), ([65, 39], 10, 10), ([69, 39], 10, 10), ([39], 10, 10), ([39], 10, 10), ([63, 36], 10, 10), ([67, 36], 10, 9), ([65, 36], 9, 9), ([70, 36], 9, 9), ([67, 36], 9, 9), ([67, 36], 9, 9), ([62, 36], 9, 9), ([36], 9, 9), ([69, 39], 9, 9), ([65, 39], 9, 10), ([65, 39], 10, 10), ([65, 39], 10, 10), ([39], 10, 10), ([63, 39], 10, 10), ([63, 39], 10, 10), ([67, 39], 10, 10), ([65, 46], 10, 10), ([65, 46], 10, 0), ([62, 46], 0, 0), ([46], 0, 0), ([67, 38], 0, 0), ([62, 38], 0, 13), ([65, 38], 13, 13), ([65, 38], 13, 13), ([67, 43], 13, 13), ([43], 13, 23), ([43], 23, 23), ([43], 23, 23), ([43], 23, 23), ([43], 23, 23), ([43], 23, 23), ([43], 23, 23)], [([42, 66, 58, 61, 66, 64], 24, 16), ([42, 70, 58, 61, 66, 64], 16, 16), ([42, 61, 58, 61, 66, 68], 16, 16), ([42, 66, 58, 61, 66, 68], 16, 16), ([42, 61, 58, 61, 66, 63], 16, 16), ([42, 70, 58, 61, 66, 63], 16, 16), ([42, 66, 58, 61, 66, 61], 16, 16), ([42, 61, 58, 61, 66, 61], 16, 16), ([44, 68, 56, 59, 63, 59], 16, 16), ([44, 71, 56, 59, 63, 59], 16, 21), ([44, 63, 56, 59, 63, 64], 21, 21), ([44, 68, 56, 59, 63, 64], 21, 21), ([44, 63, 56, 59, 63, 64], 21, 21), ([44, 71, 56, 59, 63, 64], 21, 21), ([44, 68, 56, 59, 63], 21, 21), ([44, 63, 56, 59, 63, 59], 21, 21), ([37, 61, 56, 61, 64, 64], 21, 21), ([37, 64, 56, 61, 64], 21, 7), ([37, 68, 56, 61, 64, 68], 7, 7), ([37, 61, 56, 61, 64], 7, 7), ([39, 63, 58, 63, 66, 63], 7, 7), ([39, 66, 58, 63, 66], 7, 11), ([39, 70, 58, 63, 66, 61], 11, 11), ([39, 63, 58, 63, 66, 61], 11, 11), ([37, 61, 56, 61, 64, 66], 11, 11), ([37, 64, 56, 61, 64, 63], 11, 7), ([37, 68, 56, 61, 64, 68], 7, 7), ([37, 61, 56, 61, 64, 68], 7, 7), ([37, 68, 56, 61, 64, 68], 7, 7), ([37, 64, 56, 61, 64, 68], 7, 7), ([37, 61, 56, 61, 64, 66], 7, 7), ([37, 68, 56, 61, 64, 66], 7, 7), ([47, 71, 59, 63, 66, 64], 7, 7), ([47, 63, 59, 63, 66, 64], 7, 4), ([47, 66, 59, 63, 66, 68], 4, 4), ([47, 71, 59, 63, 66, 68], 4, 4), ([47, 66, 59, 63, 66, 63], 4, 4), ([47, 63, 59, 63, 66], 4, 4), ([47, 71, 59, 63, 66, 68], 4, 4), ([47, 66, 59, 63, 66], 4, 4), ([40, 64, 56, 59, 64, 59], 4, 4), ([40, 68, 56, 59, 64, 59], 4, 14), ([40, 71, 56, 59, 64, 59], 14, 14), ([40, 64, 56, 59, 64, 59], 14, 14), ([42, 66, 58, 61, 66, 64], 14, 14), ([42, 70, 58, 61, 66], 14, 16), ([42, 61, 58, 61, 66, 61], 16, 16), ([42, 66, 58, 61, 66], 16, 16), ([37, 61, 56, 61, 64, 59], 16, 16), ([37, 64, 56, 61, 64], 16, 7), ([37, 68, 56, 61, 64, 61], 7, 7), ([37, 61, 56, 61, 64, 61], 7, 7), ([37, 68, 56, 61, 64, 64], 7, 7), ([37, 64, 56, 61, 64, 64], 7, 7), ([37, 61, 56, 61, 64, 59], 7, 7), ([37, 68, 56, 61, 64], 7, 7), ([44, 68, 56, 59, 63, 64], 7, 7), ([44, 71, 56, 59, 63, 64], 7, 21), ([44, 63, 56, 59, 63, 64], 21, 21), ([44, 68, 56, 59, 63, 64], 21, 21), ([44, 63, 56, 59, 63], 21, 21), ([44, 71, 56, 59, 63], 21, 21), ([44, 68, 56, 59, 63], 21, 21), ([44, 63, 56, 59, 63], 21, 21), ([71, 56, 59, 64, 59], 21, 21), ([68, 56, 59, 64], 21, 14), ([71, 56, 59, 64, 61], 14, 14), ([68, 56, 59, 64, 61], 14, 14), ([64, 56, 59, 64, 64], 14, 14), ([68, 56, 59, 64, 64], 14, 14), ([64, 56, 59, 64, 64], 14, 14), ([71, 56, 59, 64, 64], 14, 14), ([63, 56, 59, 63, 64], 14, 14), ([71, 56, 59, 63, 64], 14, 21), ([63, 56, 59, 63, 61], 21, 21), ([71, 56, 59, 63, 61], 21, 21), ([68, 56, 59, 63], 21, 21), ([71, 56, 59, 63], 21, 21), ([68, 56, 59, 63], 21, 21), ([63, 56, 59, 63], 21, 21), ([70, 54, 58, 63, 59], 21, 21), ([66, 54, 58, 63, 59], 21, 11), ([70, 54, 58, 63, 61], 11, 11), ([66, 54, 58, 63, 61], 11, 11), ([63, 54, 58, 63, 64], 11, 11), ([66, 54, 58, 63, 64], 11, 11), ([63, 54, 58, 63, 64], 11, 11), ([70, 54, 58, 63, 64], 11, 11), ([68, 56, 61, 64, 64], 11, 11), ([64, 56, 61, 64, 64], 11, 7), ([68, 56, 61, 64, 61], 7, 7), ([64, 56, 61, 64, 61], 7, 7), ([61, 56, 61, 64, 63], 7, 7), ([64, 56, 61, 64, 63], 7, 7), ([61, 56, 61, 64, 66], 7, 7), ([68, 56, 61, 64, 66], 7, 7), ([63, 56, 59, 63, 59], 7, 7), ([71, 56, 59, 63, 59], 7, 21), ([63, 56, 59, 63, 63], 21, 21), ([71, 56, 59, 63, 63], 21, 21), ([61, 54, 58, 61, 68], 21, 21), ([70, 54, 58, 61, 68], 21, 16), ([61, 54, 58, 61, 68], 16, 16), ([70, 54, 58, 61, 68], 16, 16), ([61, 54, 58, 61, 64], 16, 16), ([70, 54, 58, 61, 64], 16, 16), ([61, 54, 58, 61, 66], 16, 16), ([70, 54, 58, 61, 66], 16, 16), ([66, 54, 58, 61, 66], 16, 16), ([70, 54, 58, 61, 66], 16, 16), ([66, 54, 58, 61, 64], 16, 16), ([61, 54, 58, 61, 64], 16, 16), ([71, 56, 59, 64, 59], 16, 16), ([68, 56, 59, 64, 59], 16, 14), ([71, 56, 59, 64, 59], 14, 14), ([68, 56, 59, 64, 59], 14, 14), ([64, 56, 59, 64, 71], 14, 14), ([68, 56, 59, 64], 14, 14), ([64, 56, 59, 64, 64], 14, 14), ([71, 56, 59, 64, 64], 14, 14), ([63, 56, 59, 63, 64], 14, 14), ([71, 56, 59, 63, 64], 14, 21), ([63, 56, 59, 63, 64], 21, 21), ([71, 56, 59, 63, 64], 21, 21), ([68, 56, 59, 63], 21, 21), ([71, 56, 59, 63], 21, 21), ([68, 56, 59, 63], 21, 21), ([63, 56, 59, 63], 21, 21), ([71, 56, 59, 64, 59], 21, 21), ([68, 56, 59, 64], 21, 14), ([71, 56, 59, 64, 61], 14, 14), ([68, 56, 59, 64, 61], 14, 14), ([64, 56, 59, 64, 64], 14, 14), ([68, 56, 59, 64, 64], 14, 14), ([64, 56, 59, 64, 64], 14, 14), ([71, 56, 59, 64, 64], 14, 14), ([63, 56, 59, 63, 64], 14, 14), ([71, 56, 59, 63, 64], 14, 21), ([63, 56, 59, 63, 61], 21, 21), ([71, 56, 59, 63, 61], 21, 21), ([68, 56, 59, 63], 21, 21), ([71, 56, 59, 63], 21, 21), ([68, 56, 59, 63], 21, 21), ([63, 56, 59, 63], 21, 21), ([70, 54, 58, 63, 59], 21, 21), ([66, 54, 58, 63, 59], 21, 11), ([70, 54, 58, 63, 61], 11, 11), ([66, 54, 58, 63, 61], 11, 11), ([63, 54, 58, 63, 64], 11, 11), ([66, 54, 58, 63, 64], 11, 11), ([63, 54, 58, 63, 64], 11, 11), ([70, 54, 58, 63, 64], 11, 11), ([68, 56, 61, 64, 64], 11, 11), ([64, 56, 61, 64, 64], 11, 7), ([68, 56, 61, 64, 61], 7, 7), ([64, 56, 61, 64, 61], 7, 7), ([61, 56, 61, 64, 63], 7, 7), ([64, 56, 61, 64, 63], 7, 7), ([61, 56, 61, 64, 66], 7, 7), ([68, 56, 61, 64, 66], 7, 7), ([63, 56, 59, 63, 59], 7, 7), ([71, 56, 59, 63, 59], 7, 21), ([63, 56, 59, 63, 63], 21, 21), ([71, 56, 59, 63, 63], 21, 21), ([61, 54, 58, 61, 68], 21, 21), ([70, 54, 58, 61, 68], 21, 16), ([61, 54, 58, 61, 68], 16, 16), ([70, 54, 58, 61, 68], 16, 16), ([61, 54, 58, 61, 64], 16, 16), ([70, 54, 58, 61, 64], 16, 16), ([61, 54, 58, 61, 66], 16, 16), ([70, 54, 58, 61, 66], 16, 16), ([66, 54, 58, 61, 66], 16, 16), ([70, 54, 58, 61, 66], 16, 16), ([66, 54, 58, 61, 64], 16, 16), ([61, 54, 58, 61, 64], 16, 16), ([71, 56, 59, 64, 59], 16, 16), ([68, 56, 59, 64, 59], 16, 14), ([71, 56, 59, 64, 59], 14, 14), ([68, 56, 59, 64, 59], 14, 14), ([64, 56, 59, 64, 71], 14, 14), ([68, 56, 59, 64], 14, 14), ([64, 56, 59, 64, 64], 14, 14), ([71, 56, 59, 64, 64], 14, 14), ([63, 56, 59, 63, 64], 14, 14), ([71, 56, 59, 63, 64], 14, 21), ([63, 56, 59, 63, 64], 21, 21), ([71, 56, 59, 63, 64], 21, 21), ([68, 56, 59, 63], 21, 21), ([71, 56, 59, 63], 21, 21), ([68, 56, 59, 63], 21, 21), ([63, 56, 59, 63], 21, 21), ([71, 56, 59, 64, 59], 21, 21), ([68, 56, 59, 64], 21, 14), ([71, 56, 59, 64, 61], 14, 14), ([68, 56, 59, 64, 61], 14, 14), ([64, 56, 59, 64, 64], 14, 14), ([68, 56, 59, 64, 64], 14, 14), ([64, 56, 59, 64, 64], 14, 14), ([71, 56, 59, 64, 64], 14, 14), ([63, 56, 59, 63, 64], 14, 14), ([71, 56, 59, 63, 64], 14, 21), ([63, 56, 59, 63, 61], 21, 21), ([71, 56, 59, 63, 61], 21, 21), ([68, 56, 59, 63], 21, 21), ([71, 56, 59, 63], 21, 21), ([68, 56, 59, 63], 21, 21), ([63, 56, 59, 63], 21, 21), ([70, 54, 58, 63, 59], 21, 21), ([66, 54, 58, 63, 59], 21, 11), ([70, 54, 58, 63, 61], 11, 11), ([66, 54, 58, 63, 61], 11, 11), ([63, 54, 58, 63, 64], 11, 11), ([66, 54, 58, 63, 64], 11, 11), ([63, 54, 58, 63, 64], 11, 11), ([70, 54, 58, 63, 64], 11, 11), ([68, 56, 61, 64, 64], 11, 11), ([64, 56, 61, 64, 64], 11, 7), ([68, 56, 61, 64, 61], 7, 7), ([64, 56, 61, 64, 61], 7, 7), ([61, 56, 61, 64, 63], 7, 7), ([64, 56, 61, 64, 63], 7, 7), ([61, 56, 61, 64, 66], 7, 7), ([68, 56, 61, 64, 66], 7, 7), ([63, 56, 59, 63, 59], 7, 7), ([71, 56, 59, 63, 59], 7, 21), ([63, 56, 59, 63, 63], 21, 21), ([71, 56, 59, 63, 63], 21, 21), ([61, 54, 58, 61, 68], 21, 21), ([70, 54, 58, 61, 68], 21, 16), ([61, 54, 58, 61, 68], 16, 16), ([70, 54, 58, 61, 68], 16, 16), ([61, 54, 58, 61, 64], 16, 16), ([70, 54, 58, 61, 64], 16, 16), ([61, 54, 58, 61, 66], 16, 16), ([70, 54, 58, 61, 66], 16, 16), ([66, 54, 58, 61, 66], 16, 16), ([70, 54, 58, 61, 66], 16, 16), ([66, 54, 58, 61, 64], 16, 16), ([61, 54, 58, 61, 64], 16, 16), ([71, 56, 59, 64, 59], 16, 16), ([68, 56, 59, 64, 59], 16, 14), ([71, 56, 59, 64, 59], 14, 14), ([68, 56, 59, 64, 59], 14, 14), ([64, 56, 59, 64, 71], 14, 14), ([68, 56, 59, 64], 14, 14), ([64, 56, 59, 64, 64], 14, 14), ([71, 56, 59, 64, 64], 14, 14), ([63, 56, 59, 63, 64], 14, 14), ([71, 56, 59, 63, 64], 14, 21), ([63, 56, 59, 63, 64], 21, 21), ([71, 56, 59, 63, 64], 21, 21), ([68, 56, 59, 63], 21, 21), ([71, 56, 59, 63], 21, 21), ([68, 56, 59, 63], 21, 21), ([63, 56, 59, 63], 21, 21), ([42], 21, 21), ([42], 21, 16), ([42, 76], 16, 16), ([42, 70], 16, 16), ([42, 70], 16, 16), ([42], 16, 16), ([42, 70], 16, 16), ([42, 68], 16, 16), ([40], 16, 16), ([40], 16, 14), ([40, 73], 14, 14), ([40, 73], 14, 14), ([40, 68], 14, 14), ([40], 14, 14), ([40, 73], 14, 14), ([40, 73], 14, 14), ([44, 76], 14, 14), ([44, 76], 14, 21), ([44, 76], 21, 21), ([44, 76], 21, 21), ([44, 73], 21, 21), ([44], 21, 21), ([44, 76], 21, 21), ([44, 76], 21, 21), ([44, 76], 21, 21), ([44, 76], 21, 21), ([44, 76], 21, 21), ([44, 70], 21, 21), ([44, 70], 21, 21), ([44, 70], 21, 21), ([44, 73], 21, 21), ([44, 73], 21, 21), ([37, 68], 21, 21), ([37, 68], 21, 7), ([37, 68], 7, 7), ([37, 68], 7, 7), ([42, 71], 7, 7), ([42, 71], 7, 16), ([42, 71], 16, 16), ([42, 71], 16, 16), ([42], 16, 16), ([42], 16, 16), ([42, 76], 16, 16), ([42, 76], 16, 16), ([42, 68], 16, 16), ([42, 75], 16, 16), ([42, 76], 16, 16), ([42, 76], 16, 16), ([47, 76], 16, 16), ([47, 76], 16, 4), ([47, 76], 4, 4), ([47, 76], 4, 4), ([47, 75], 4, 4), ([47, 76], 4, 4), ([47, 68], 4, 4), ([47], 4, 4), ([42, 71], 4, 4), ([42, 76], 4, 16), ([42, 71], 16, 16), ([42, 70], 16, 16), ([42, 75], 16, 16), ([42], 16, 16), ([42, 71], 16, 16), ([42, 71], 16, 16), ([44, 68], 16, 16), ([44, 68], 16, 21), ([44, 75], 21, 21), ([44, 73], 21, 21), ([44, 76], 21, 21), ([44], 21, 21), ([44, 71], 21, 21), ([44, 75], 21, 21), ([47, 68], 21, 21), ([47, 68], 21, 4), ([47, 70], 4, 4), ([47, 70], 4, 4), ([47, 70], 4, 4), ([47, 70], 4, 4), ([47, 71], 4, 4), ([47, 71], 4, 4), ([37, 73], 4, 4), ([37], 4, 7), ([37], 7, 7), ([37, 68], 7, 7), ([37, 73], 7, 7), ([37, 73], 7, 7), ([37, 73], 7, 7), ([37, 73], 7, 7), ([47, 71], 7, 7), ([47, 71], 7, 4), ([47, 71], 4, 4), ([47, 71], 4, 4), ([47], 4, 4), ([47], 4, 4), ([47], 4, 4), ([47], 4, 4), ([42], 4, 4), ([42], 4, 16), ([42, 76], 16, 16), ([42, 70], 16, 16), ([42, 70], 16, 16), ([42], 16, 16), ([42, 70], 16, 16), ([42, 68], 16, 16), ([40], 16, 16), ([40], 16, 14), ([40, 73], 14, 14), ([40, 73], 14, 14), ([40, 68], 14, 14), ([40], 14, 14), ([40, 73], 14, 14), ([40, 73], 14, 14), ([44, 76], 14, 14), ([44, 76], 14, 21), ([44, 76], 21, 21), ([44, 76], 21, 21), ([44, 73], 21, 21), ([44], 21, 21), ([44, 76], 21, 21), ([44, 76], 21, 21), ([44, 76], 21, 21), ([44, 76], 21, 21), ([44, 76], 21, 21), ([44, 70], 21, 21), ([44, 70], 21, 21), ([44, 70], 21, 21), ([44, 73], 21, 21), ([44, 73], 21, 21), ([37, 68], 21, 21), ([37, 68], 21, 7), ([37, 68], 7, 7), ([37, 68], 7, 7), ([42, 71], 7, 7), ([42, 71], 7, 16), ([42, 71], 16, 16), ([42, 71], 16, 16), ([42], 16, 16), ([42], 16, 16), ([42, 76], 16, 16), ([42, 76], 16, 16), ([42, 68], 16, 16), ([42, 75], 16, 16), ([42, 76], 16, 16), ([42, 76], 16, 16), ([47, 76], 16, 16), ([47, 76], 16, 4), ([47, 76], 4, 4), ([47, 76], 4, 4), ([47, 75], 4, 4), ([47, 76], 4, 4), ([47, 68], 4, 4), ([47], 4, 4), ([42, 71], 4, 4), ([42, 76], 4, 16), ([42, 71], 16, 16), ([42, 70], 16, 16), ([42, 75], 16, 16), ([42], 16, 16), ([42, 71], 16, 16), ([42, 71], 16, 16), ([44, 68], 16, 16), ([44, 68], 16, 21), ([44, 75], 21, 21), ([44, 73], 21, 21), ([44, 76], 21, 21), ([44], 21, 21), ([44, 71], 21, 21), ([44, 75], 21, 21), ([47, 68], 21, 21), ([47, 68], 21, 4), ([47, 70], 4, 4), ([47, 70], 4, 4), ([47, 70], 4, 4), ([47, 70], 4, 4), ([47, 71], 4, 4), ([47, 71], 4, 4), ([37, 73], 4, 4), ([37], 4, 7), ([37], 7, 7), ([37, 68], 7, 7), ([37, 73], 7, 7), ([37, 73], 7, 7), ([37, 73], 7, 7), ([37, 73], 7, 7), ([47, 71], 7, 7), ([47, 71], 7, 4), ([47, 71], 4, 4), ([47, 71], 4, 4), ([47], 4, 4), ([47], 4, 4), ([47], 4, 4), ([47], 4, 4), ([42], 4, 4), ([42], 4, 16), ([42, 76], 16, 16), ([42, 70], 16, 16), ([42, 70], 16, 16), ([42], 16, 16), ([42, 70], 16, 16), ([42, 68], 16, 16), ([40], 16, 16), ([40], 16, 14), ([40, 73], 14, 14), ([40, 73], 14, 14), ([40, 68], 14, 14), ([40], 14, 14), ([40, 73], 14, 14), ([40, 73], 14, 14), ([44, 76], 14, 14), ([44, 76], 14, 21), ([44, 76], 21, 21), ([44, 76], 21, 21), ([44, 73], 21, 21), ([44], 21, 21), ([44, 76], 21, 21), ([44, 76], 21, 21), ([44, 76], 21, 21), ([44, 76], 21, 21), ([44, 76], 21, 21), ([44, 70], 21, 21), ([44, 70], 21, 21), ([44, 70], 21, 21), ([44, 73], 21, 21), ([44, 73], 21, 21), ([37, 68], 21, 21), ([37, 68], 21, 7), ([37, 68], 7, 7), ([37, 68], 7, 7), ([42, 71], 7, 7), ([42, 71], 7, 16), ([42, 71], 16, 16), ([42, 71], 16, 16), ([42], 16, 16), ([42], 16, 16), ([42, 76], 16, 16), ([42, 76], 16, 16), ([42, 68], 16, 16), ([42, 75], 16, 16), ([42, 76], 16, 16), ([42, 76], 16, 16), ([47, 76], 16, 16), ([47, 76], 16, 4), ([47, 76], 4, 4), ([47, 76], 4, 4), ([47, 75], 4, 4), ([47, 76], 4, 4), ([47, 68], 4, 4), ([47], 4, 4), ([42, 71], 4, 4), ([42, 76], 4, 16), ([42, 71], 16, 16), ([42, 70], 16, 16), ([42, 75], 16, 16), ([42], 16, 16), ([42, 71], 16, 16), ([42, 71], 16, 16), ([44, 68], 16, 16), ([44, 68], 16, 21), ([44, 75], 21, 21), ([44, 73], 21, 21), ([44, 76], 21, 21), ([44], 21, 21), ([44, 71], 21, 21), ([44, 75], 21, 21), ([47, 68], 21, 21), ([47, 68], 21, 4), ([47, 70], 4, 4), ([47, 70], 4, 4), ([47, 70], 4, 4), ([47, 70], 4, 4), ([47, 71], 4, 4), ([47, 71], 4, 4), ([37, 73], 4, 4), ([37], 4, 7), ([37], 7, 7), ([37, 68], 7, 7), ([37, 73], 7, 7), ([37, 73], 7, 7), ([37, 73], 7, 7), ([37, 73], 7, 7), ([47, 71], 7, 7), ([47, 71], 7, 4), ([47, 71], 4, 4), ([47, 71], 4, 4), ([47], 4, 4), ([47], 4, 4), ([47], 4, 4), ([47], 4, 4)]]\n"]}],"source":["# create aligned data for every onset and beatinfo file\n","\n","all_data = []\n","i = 0\n","\n","while i < 1000:\n","    i += 1\n","    onset_path = os.path.join(working_dir, f\"{i :04d}_onset_condensed.csv\")\n","    beatinfo_path = os.path.join(working_dir, f\"{i :04d}_beatinfo.csv\")\n","    onsets = pd.read_csv(onset_path)\n","    beatinfo = pd.read_csv(beatinfo_path)\n","    all_data.append(align_onsets_with_chords(onsets, beatinfo))\n","    if i % 50 == 0:\n","        print(i)\n","\n","print(all_data[0:2])\n","#print(all_data[0:20])"]},{"cell_type":"code","execution_count":6,"id":"183823af","metadata":{"execution":{"iopub.execute_input":"2025-04-15T09:23:35.479574Z","iopub.status.busy":"2025-04-15T09:23:35.479321Z","iopub.status.idle":"2025-04-15T09:25:01.998423Z","shell.execute_reply":"2025-04-15T09:25:01.997541Z"},"papermill":{"duration":86.551252,"end_time":"2025-04-15T09:25:02.02594","exception":false,"start_time":"2025-04-15T09:23:35.474688","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"functional\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ prev_chords (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ notes (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │ prev_chords[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ notes[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n","│                           │                        │                │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ not_equal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ any (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Any</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">139,776</span> │ masking[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n","│                           │                        │                │ any[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,096</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ prev_chords (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ notes (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m400\u001b[0m │ prev_chords[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ notes[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n","│                           │                        │                │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ not_equal (\u001b[38;5;33mNotEqual\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ masking (\u001b[38;5;33mMasking\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ any (\u001b[38;5;33mAny\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ lstm (\u001b[38;5;33mLSTM\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m139,776\u001b[0m │ masking[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n","│                           │                        │                │ any[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)       │          \u001b[38;5;34m3,096\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">143,272</span> (559.66 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m143,272\u001b[0m (559.66 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">143,272</span> (559.66 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m143,272\u001b[0m (559.66 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - accuracy: 0.6528 - loss: 1.8084 - val_accuracy: 0.8620 - val_loss: 0.5976\n","Epoch 2/10\n","\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.8902 - loss: 0.4655 - val_accuracy: 0.9510 - val_loss: 0.1811\n","Epoch 3/10\n","\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9583 - loss: 0.1616 - val_accuracy: 0.9779 - val_loss: 0.0988\n","Epoch 4/10\n","\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9784 - loss: 0.0974 - val_accuracy: 0.9877 - val_loss: 0.0692\n","Epoch 5/10\n","\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9857 - loss: 0.0725 - val_accuracy: 0.9906 - val_loss: 0.0536\n","Epoch 6/10\n","\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9889 - loss: 0.0587 - val_accuracy: 0.9914 - val_loss: 0.0457\n","Epoch 7/10\n","\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9891 - loss: 0.0534 - val_accuracy: 0.9924 - val_loss: 0.0402\n","Epoch 8/10\n","\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9909 - loss: 0.0452 - val_accuracy: 0.9928 - val_loss: 0.0369\n","Epoch 9/10\n","\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9919 - loss: 0.0401 - val_accuracy: 0.9930 - val_loss: 0.0341\n","Epoch 10/10\n","\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9915 - loss: 0.0402 - val_accuracy: 0.9937 - val_loss: 0.0324\n","True Chords:      [20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 19, 19, 19, 19, 19, 19, 19, 9, 9, 9, 9, 9, 9, 9, 9, 19, 19, 19, 19, 19, 19, 19, 19, 10, 10, 10, 10, 10, 10, 10, 10, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 9, 9, 9, 9, 9, 9, 9, 9, 20, 20, 20, 20, 20, 20, 20, 20, 10, 10, 10, 10, 10, 10, 10, 10, 9, 9, 9, 9, 20, 20, 20, 20, 9, 9, 9, 9, 9, 9, 9, 9, 6, 6, 6, 6, 9, 9, 9, 9, 1, 1, 1, 1, 1, 1, 1, 1, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 20, 22, 22, 22, 22, 22, 22, 22, 22, 8, 8, 8, 8, 8, 8, 8, 8, 22, 22, 22, 22, 22, 22, 22, 22, 13, 13, 13, 13, 13, 13, 13, 13, 8, 8, 8, 8, 8, 8, 8, 8, 13, 13, 13, 13, 13, 13, 13, 13, 22, 22, 22, 22, 22, 22, 22, 22, 8, 8, 8, 8, 8, 8, 8, 8, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 22, 22, 22, 22, 3, 3, 3, 3, 18, 18, 18, 18, 18, 18, 18, 18, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 15, 15, 15, 15, 8, 8, 8, 8, 8, 8, 8, 8, 3, 3, 3, 3, 3, 3, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 10, 10, 10, 10, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 9, 9, 9, 9, 9, 9, 9, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 19, 19, 19, 19, 19, 19, 19, 9, 9, 9, 9, 9, 9, 9, 9, 19, 19, 19, 19, 19, 19, 19, 19, 10, 10, 10, 10, 10, 10, 10, 10, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 9, 9, 9, 9, 9, 9, 9, 9, 20, 20, 20, 20, 20, 20, 20, 20, 10, 10, 10, 10, 10, 10, 10, 10, 9, 9, 9, 9, 20, 20, 20, 20, 9, 9, 9, 9, 9, 9, 9, 9, 6, 6, 6, 6, 9, 9, 9, 9, 1, 1, 1, 1, 1, 1, 1, 1, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 20, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 10, 10, 10, 10, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 9, 9, 9, 9, 9, 9, 9, 9, 20, 20, 20, 20, 20, 20, 20]\n","Predicted Chords: [9, 20, 20, 20, 20, 20, 20, 20, 20, 19, 19, 19, 19, 19, 19, 19, 19, 9, 9, 9, 9, 9, 9, 9, 9, 19, 19, 19, 19, 19, 19, 19, 19, 10, 10, 10, 10, 10, 10, 10, 10, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 9, 9, 9, 9, 9, 9, 9, 9, 20, 20, 20, 20, 20, 20, 20, 20, 10, 10, 10, 10, 10, 10, 10, 10, 9, 9, 9, 9, 20, 20, 20, 20, 9, 9, 9, 9, 9, 9, 9, 9, 6, 6, 6, 6, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 20, 23, 23, 23, 23, 23, 23, 23, 23, 8, 8, 8, 8, 8, 8, 8, 8, 22, 22, 22, 22, 22, 22, 22, 22, 13, 13, 13, 13, 13, 13, 13, 13, 8, 8, 8, 8, 8, 8, 8, 8, 13, 13, 13, 13, 13, 13, 13, 13, 22, 22, 22, 22, 22, 22, 22, 22, 8, 8, 8, 8, 8, 8, 8, 8, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 22, 22, 22, 22, 3, 3, 3, 3, 18, 18, 18, 18, 18, 18, 18, 18, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 15, 15, 15, 15, 8, 8, 8, 8, 8, 8, 8, 8, 3, 3, 3, 3, 3, 3, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 10, 10, 10, 10, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 9, 9, 9, 9, 9, 9, 9, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 19, 19, 19, 19, 19, 19, 19, 9, 9, 9, 9, 9, 9, 9, 9, 19, 19, 19, 19, 19, 19, 19, 19, 10, 10, 10, 10, 10, 10, 10, 10, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 9, 9, 9, 9, 9, 9, 9, 9, 20, 20, 20, 20, 20, 20, 20, 20, 10, 10, 10, 10, 10, 10, 10, 10, 9, 9, 9, 9, 20, 20, 20, 20, 9, 9, 9, 9, 9, 9, 9, 9, 6, 6, 6, 6, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 20, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 10, 10, 10, 10, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 9, 9, 9, 9, 9, 9, 9, 9, 20, 20, 20, 20, 20, 20, 20]\n","Confidences:  [0.25641024112701416, 0.6516817808151245, 0.9756951332092285, 0.9963440299034119, 0.999245285987854, 0.9994608759880066, 0.9996155500411987, 0.9994795918464661, 0.987021267414093, 0.883749783039093, 0.9936503767967224, 0.9960065484046936, 0.9977255463600159, 0.9980373978614807, 0.9982247948646545, 0.997984766960144, 0.8189383745193481, 0.9718197584152222, 0.9978700876235962, 0.9992045760154724, 0.9992069602012634, 0.9989218711853027, 0.9986697435379028, 0.9985902905464172, 0.9647858142852783, 0.8428476452827454, 0.9803506731987, 0.9935519695281982, 0.9970927238464355, 0.997688889503479, 0.99801105260849, 0.9978146553039551, 0.867874026298523, 0.9853366017341614, 0.9983136653900146, 0.9991260170936584, 0.9991686344146729, 0.999024510383606, 0.9988698363304138, 0.9987982511520386, 0.970893383026123, 0.8541983366012573, 0.9802302122116089, 0.9945664405822754, 0.9976657629013062, 0.998083233833313, 0.9982994198799133, 0.9980321526527405, 0.9980736970901489, 0.9977788329124451, 0.9979065656661987, 0.9976696372032166, 0.9978356957435608, 0.997624933719635, 0.9978141784667969, 0.9976213574409485, 0.8170720338821411, 0.9722734093666077, 0.9979015588760376, 0.9991998076438904, 0.9991926550865173, 0.9989025592803955, 0.9986540079116821, 0.9985833168029785, 0.8870887160301208, 0.946300745010376, 0.9988839030265808, 0.9993222951889038, 0.999414324760437, 0.9990394711494446, 0.9991899132728577, 0.9990758895874023, 0.9358933568000793, 0.9768925905227661, 0.9980267882347107, 0.9991239905357361, 0.9991706609725952, 0.9990411400794983, 0.9989145994186401, 0.9988470077514648, 0.9540470838546753, 0.9647300839424133, 0.9985737800598145, 0.9990103244781494, 0.9326798915863037, 0.9167612195014954, 0.998839795589447, 0.9992548823356628, 0.9724550247192383, 0.8642356991767883, 0.9985463619232178, 0.999413251876831, 0.9993423819541931, 0.9990746974945068, 0.9988045692443848, 0.9986791014671326, 0.9566736221313477, 0.9260227680206299, 0.996134877204895, 0.9986019730567932, 0.9341110587120056, 0.9554530382156372, 0.9983224272727966, 0.9992578625679016, 0.9820727109909058, 0.49660852551460266, 0.9911892414093018, 0.9936229586601257, 0.9658337235450745, 0.9748674035072327, 0.9524507522583008, 0.9795438647270203, 0.9607417583465576, 0.9475148916244507, 0.9991500377655029, 0.999481737613678, 0.9993810653686523, 0.9992259740829468, 0.9990918636322021, 0.9990012049674988, 0.9692087173461914, 0.9614688158035278, 0.9977725148200989, 0.9989627599716187, 0.9993521571159363, 0.9990609288215637, 0.999212384223938, 0.9990547299385071, 0.9415157437324524, 0.6764816641807556, 0.9332095980644226, 0.9647551774978638, 0.9598121047019958, 0.9490047693252563, 0.929856538772583, 0.92100989818573, 0.8855016827583313, 0.7613102197647095, 0.9775263071060181, 0.9962511658668518, 0.9972171783447266, 0.9970927238464355, 0.9970493316650391, 0.996920108795166, 0.9022191166877747, 0.9117192029953003, 0.9919497966766357, 0.9967160224914551, 0.9973037242889404, 0.9973688125610352, 0.9973727464675903, 0.9976468682289124, 0.9518494009971619, 0.8643695712089539, 0.9943485856056213, 0.9971580505371094, 0.996222972869873, 0.9967139959335327, 0.9970903396606445, 0.9974939823150635, 0.9466263651847839, 0.9557691216468811, 0.9975818395614624, 0.9988396763801575, 0.9985887408256531, 0.9982820749282837, 0.998087465763092, 0.9979494214057922, 0.9676331281661987, 0.886187732219696, 0.9955348968505859, 0.998387336730957, 0.9984283447265625, 0.9982714653015137, 0.9981215596199036, 0.9974060654640198, 0.911177396774292, 0.8149490356445312, 0.9877562522888184, 0.9971349239349365, 0.9980559349060059, 0.997962236404419, 0.9976006150245667, 0.9976709485054016, 0.9618958234786987, 0.9499838352203369, 0.9974287152290344, 0.9987391829490662, 0.9985274076461792, 0.9983764886856079, 0.9974163770675659, 0.9975284934043884, 0.9035730957984924, 0.9152259826660156, 0.9983914494514465, 0.9992144107818604, 0.9986172914505005, 0.9980257749557495, 0.9978517293930054, 0.9984214305877686, 0.9976525902748108, 0.9967306852340698, 0.9960541725158691, 0.9960171580314636, 0.9972381591796875, 0.9980529546737671, 0.9977806210517883, 0.9980098605155945, 0.640605628490448, 0.9575834274291992, 0.9970712661743164, 0.998898983001709, 0.9357643723487854, 0.9594619274139404, 0.9978393316268921, 0.9991828799247742, 0.9312241673469543, 0.9644445776939392, 0.9987251162528992, 0.9992592930793762, 0.999275267124176, 0.9992460012435913, 0.9992214441299438, 0.9990345239639282, 0.8678697943687439, 0.9377904534339905, 0.9961150884628296, 0.9985632300376892, 0.998489260673523, 0.9976352453231812, 0.9966249465942383, 0.9960756897926331, 0.9956737160682678, 0.9976116418838501, 0.9973297119140625, 0.9979497790336609, 0.9264320731163025, 0.9302482008934021, 0.9978316426277161, 0.9983680844306946, 0.9169588088989258, 0.8913026452064514, 0.9985405206680298, 0.9991714954376221, 0.9987221360206604, 0.9987438321113586, 0.9982325434684753, 0.998282790184021, 0.9188587665557861, 0.9181978702545166, 0.9986400008201599, 0.9993382096290588, 0.9989344477653503, 0.9981743097305298, 0.9972512125968933, 0.996560275554657, 0.7125273942947388, 0.8030422329902649, 0.9956570863723755, 0.998200535774231, 0.9991812109947205, 0.9988693594932556, 0.9991138577461243, 0.9989271759986877, 0.9984192848205566, 0.9980179071426392, 0.9979532957077026, 0.9979262351989746, 0.8619673252105713, 0.9845820069313049, 0.9992921352386475, 0.9996389150619507, 0.9681508541107178, 0.9596312642097473, 0.9988694787025452, 0.9991846680641174, 0.9996205568313599, 0.9993815422058105, 0.9995203018188477, 0.9992409944534302, 0.9435151219367981, 0.9530354142189026, 0.996907651424408, 0.9986844658851624, 0.9991812109947205, 0.9990687966346741, 0.9991921782493591, 0.9990416169166565, 0.9990347623825073, 0.998941957950592, 0.9987545013427734, 0.9988310933113098, 0.9990562796592712, 0.99893718957901, 0.9991556406021118, 0.998965859413147, 0.9408037662506104, 0.7589482665061951, 0.9929826259613037, 0.998407781124115, 0.9994220733642578, 0.9994445443153381, 0.9993996620178223, 0.9994658827781677, 0.9610365033149719, 0.9677739143371582, 0.999208390712738, 0.9996974468231201, 0.9806159138679504, 0.945884644985199, 0.9989868998527527, 0.9995496869087219, 0.9685434103012085, 0.9653822779655457, 0.9981328845024109, 0.9988691210746765, 0.9996360540390015, 0.9996678829193115, 0.9995545744895935, 0.9992225170135498, 0.8197748064994812, 0.9056816101074219, 0.9951778650283813, 0.9985514283180237, 0.8793123364448547, 0.9873316884040833, 0.9968808889389038, 0.9982247948646545, 0.9979427456855774, 0.9960218071937561, 0.997358500957489, 0.9981943964958191, 0.9988865256309509, 0.9993042945861816, 0.999366819858551, 0.9991094470024109, 0.9416579008102417, 0.9769105911254883, 0.9975457787513733, 0.9990435242652893, 0.9993022680282593, 0.9991539716720581, 0.9989736080169678, 0.9986340403556824, 0.9548202753067017, 0.9449469447135925, 0.9995494484901428, 0.9997755885124207, 0.9996918439865112, 0.999482274055481, 0.9993657469749451, 0.9992305040359497, 0.9988534450531006, 0.9985318183898926, 0.99831223487854, 0.9982624650001526, 0.9989309906959534, 0.9989104270935059, 0.9992513060569763, 0.9991558790206909, 0.973689079284668, 0.9314256906509399, 0.9948931932449341, 0.9966316819190979, 0.997952938079834, 0.9981217980384827, 0.9982398748397827, 0.997965931892395, 0.8147396445274353, 0.971831202507019, 0.9978559613227844, 0.9991973042488098, 0.9991990923881531, 0.9989145994186401, 0.9986649751663208, 0.9985874891281128, 0.9648655652999878, 0.8447585701942444, 0.9806062579154968, 0.9936028122901917, 0.9971054196357727, 0.9976935982704163, 0.9980127811431885, 0.9978154897689819, 0.8677639961242676, 0.9853140115737915, 0.9983110427856445, 0.9991248250007629, 0.9991679191589355, 0.9990241527557373, 0.9988694787025452, 0.9987980127334595, 0.970896303653717, 0.8542995452880859, 0.9802419543266296, 0.9945681095123291, 0.9976660013198853, 0.9980833530426025, 0.9982994198799133, 0.9980320334434509, 0.9980735778808594, 0.9977788329124451, 0.9979065656661987, 0.9976696372032166, 0.9978356957435608, 0.9976248145103455, 0.9978141784667969, 0.9976213574409485, 0.8170710802078247, 0.9722732305526733, 0.9979015588760376, 0.9991998076438904, 0.9991926550865173, 0.9989025592803955, 0.9986540079116821, 0.9985833168029785, 0.8870887160301208, 0.9463008642196655, 0.9988839030265808, 0.9993222951889038, 0.999414324760437, 0.9990394711494446, 0.9991899132728577, 0.9990758895874023, 0.9358934760093689, 0.9768925905227661, 0.9980267882347107, 0.9991239905357361, 0.9991706609725952, 0.9990411400794983, 0.9989145994186401, 0.9988470077514648, 0.9540470242500305, 0.9647300839424133, 0.9985737800598145, 0.9990103244781494, 0.9326798915863037, 0.9167611002922058, 0.998839795589447, 0.9992548823356628, 0.9724550247192383, 0.8642358183860779, 0.9985463619232178, 0.999413251876831, 0.9993423819541931, 0.9990746974945068, 0.9988045692443848, 0.9986791014671326, 0.9566736221313477, 0.9260227680206299, 0.996134877204895, 0.9986019730567932, 0.9341110587120056, 0.9554530382156372, 0.9983224272727966, 0.9992578625679016, 0.9820727109909058, 0.49660852551460266, 0.9911892414093018, 0.9936228394508362, 0.965833842754364, 0.9748674035072327, 0.9524507522583008, 0.9795438647270203, 0.9607417583465576, 0.9475148916244507, 0.9991500377655029, 0.999481737613678, 0.9993810653686523, 0.9992259740829468, 0.9990918636322021, 0.9990012049674988, 0.9692087173461914, 0.9614688158035278, 0.9977725148200989, 0.9989627599716187, 0.9993521571159363, 0.9990609288215637, 0.999212384223938, 0.9990547299385071, 0.9898440837860107, 0.9697496294975281, 0.9984681010246277, 0.9991028308868408, 0.9995680451393127, 0.9993745684623718, 0.9994226694107056, 0.9992783665657043, 0.9989637136459351, 0.9986100196838379, 0.99842369556427, 0.9982523322105408, 0.854537308216095, 0.9847278594970703, 0.9992679953575134, 0.9996203184127808, 0.9679810404777527, 0.9597350358963013, 0.9989042282104492, 0.9992150068283081, 0.9996274709701538, 0.9993935823440552, 0.9995225667953491, 0.9992474317550659, 0.943010687828064, 0.9544515609741211, 0.9969614148139954, 0.9986947178840637, 0.9991839528083801, 0.9990712404251099, 0.9991934895515442, 0.9990425705909729, 0.9990352392196655, 0.9989420771598816, 0.9987548589706421, 0.9988314509391785, 0.9990563988685608, 0.99893718957901, 0.9991557598114014, 0.9989659786224365, 0.940809428691864, 0.7589497566223145, 0.9929827451705933, 0.998407781124115, 0.9994220733642578, 0.9994445443153381, 0.9993996620178223, 0.9994660019874573, 0.9610370397567749, 0.9677737951278687, 0.999208390712738, 0.9996974468231201, 0.9806160926818848, 0.9458841681480408, 0.9989868998527527, 0.9995496869087219, 0.9685436487197876, 0.9653820395469666, 0.9981328845024109, 0.9988691210746765, 0.9996360540390015, 0.9996678829193115, 0.9995545744895935, 0.9992225170135498, 0.8197749853134155, 0.9056817293167114, 0.9951778650283813, 0.9985514283180237, 0.8793125152587891, 0.9873316884040833, 0.9968808889389038, 0.9982247948646545, 0.9979427456855774, 0.9960218071937561, 0.997358500957489, 0.9981943964958191, 0.9988865256309509, 0.9993042945861816, 0.999366819858551, 0.9991094470024109, 0.9416578412055969, 0.9769105911254883, 0.9975457787513733, 0.9990435242652893, 0.9993022680282593, 0.9991539716720581, 0.9989736080169678, 0.9986340403556824, 0.9548202753067017, 0.9449469447135925, 0.9995494484901428, 0.9997755885124207, 0.9996918439865112, 0.999482274055481, 0.9993657469749451, 0.9992305040359497]\n"]}],"source":["# --- Setup ---\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import LSTM, Dense, Masking, Input, Embedding, Concatenate\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# --- Constants ---\n","NUM_MIDI_NOTES = 128\n","NUM_CHORDS = 24\n","CHORD_INPUT_DIM = NUM_CHORDS + 1  # +1 for 'None'\n","INPUT_DIM = NUM_MIDI_NOTES + CHORD_INPUT_DIM\n","\n","# --- Utility Functions ---\n","def notes_to_vector(notes):\n","    vec = np.zeros(NUM_MIDI_NOTES)\n","    for n in notes:\n","        if 0 <= n < NUM_MIDI_NOTES:\n","            vec[n] = 1\n","    return vec\n","\n","def build_input_sequence(sequences):\n","    note_seqs, chord_seqs, y_seqs = [], [], []\n","    for seq in sequences:\n","        note_seq, chord_seq, y_seq = [], [], []\n","        for notes, prev_chord, current_chord in seq:\n","            note_vec = notes_to_vector(notes)\n","            chord_idx = prev_chord if prev_chord is not None else NUM_CHORDS\n","            note_seq.append(note_vec)\n","            chord_seq.append(chord_idx)\n","            y_seq.append(current_chord)\n","        note_seqs.append(note_seq)\n","        chord_seqs.append(chord_seq)\n","        y_seqs.append(y_seq)\n","\n","    note_padded = pad_sequences(note_seqs, padding='post', dtype='float32')\n","    chord_padded = pad_sequences(chord_seqs, padding='post', dtype='int32')\n","    y_padded = pad_sequences(y_seqs, padding='post', dtype='int32')\n","    return note_padded, chord_padded, y_padded\n","\n","def notes_to_pitch_class_vector(notes):\n","    vec = np.zeros(12)\n","    for note in notes:\n","        vec[note % 12] += 1\n","    return vec\n","\n","def normalize_pitch_class_set(notes):\n","    return tuple(sorted(note % 12 for note in notes))\n","\n","def best_chord_match(notes, chord_templates, verbose=False):\n","    input_set = set(notes)\n","    input_pc_set = normalize_pitch_class_set(notes)\n","    formatted_notes = notes_to_pitch_class_vector(notes).reshape(-1, 1)\n","\n","    best_label = 24  # default label if no match\n","    best_score = -1\n","    best_overlap = -1\n","\n","    \"\"\"# First pass: check for exact pitch class match\n","    for label, chord_notes in chord_templates.items():\n","        if normalize_pitch_class_set(chord_notes) == input_pc_set:\n","            if verbose:\n","                print(f\"Exact match found: {label}\")\n","            return label\"\"\"\n","\n","    # Second pass: compute cosine similarity for candidates with any overlap\n","    for chord_label, chord_notes in chord_templates.items():\n","        template_set = set(chord_notes)\n","        if len(input_set & template_set) == 0:\n","            continue  # skip chords with no shared notes\n","\n","        formatted_chord = notes_to_pitch_class_vector(chord_notes).reshape(-1, 1)\n","        curr_score = cosine_similarity(formatted_notes, formatted_chord)[0][0]\n","        overlap_size = len(input_set & template_set)\n","\n","        if verbose:\n","            print(f\"Comparing with {chord_label}: cosine={curr_score:.3f}, overlap={overlap_size}\")\n","\n","        if (curr_score > best_score or\n","            (curr_score == best_score and overlap_size > best_overlap)):\n","            best_score = curr_score\n","            best_overlap = overlap_size\n","            best_label = chord_label\n","\n","    return best_label\n","    \n","# --- Train/Test Split ---\n","train_data, test_data = train_test_split(all_data, test_size=0.2) # random_state=42\n","\n","# --- Vectorize ---\n","note_train, chord_train, y_train = build_input_sequence(train_data)\n","note_test, chord_test, y_test = build_input_sequence(test_data)\n","\n","# --- Model ---\n","note_input = Input(shape=(None, NUM_MIDI_NOTES), name='notes')\n","chord_input = Input(shape=(None,), dtype='int32', name='prev_chords')\n","\n","# Embed previous chord (25 possible values → 16-dim vectors)\n","chord_embedding = Embedding(input_dim=CHORD_INPUT_DIM, output_dim=16)(chord_input)\n","\n","# Combine note vector and chord embedding\n","combined_input = Concatenate()([note_input, chord_embedding])\n","\n","x = Masking(mask_value=0.0)(combined_input)\n","x = LSTM(128, return_sequences=True)(x)\n","output = Dense(NUM_CHORDS, activation='softmax')(x)\n","\n","model = Model(inputs=[note_input, chord_input], outputs=output)\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.summary()\n","\n","# --- Train ---\n","model.fit(\n","    [note_train, chord_train],\n","    y_train,\n","    epochs=10,\n","    batch_size=8,\n","    validation_split=0.2\n",")\n","\n","# --- Inference Function ---\n","def predict_chords(model, note_sequence):\n","    note_inputs = []\n","    chord_inputs = []\n","    predictions = []\n","    confidences = []\n","    prev_chord = NUM_CHORDS  # 'None'\n","\n","    for notes in note_sequence:\n","        note_vec = notes_to_vector(notes)\n","        note_inputs.append(note_vec)\n","        chord_inputs.append(prev_chord)\n","\n","        X_notes = np.array(note_inputs)[np.newaxis, :, :]\n","        X_chords = np.array(chord_inputs)[np.newaxis, :]\n","        pred = model.predict([X_notes, X_chords], verbose=0)[0, -1]\n","        prev_chord = np.argmax(pred)\n","        confidence = float(np.max(pred))\n","        if confidence < 0.40:\n","            prev_chord = best_chord_match(notes, midi_chord_dict)\n","        predictions.append(prev_chord)\n","        confidences.append(confidence)\n","\n","    return predictions, confidences\n","\n","# --- Test on One Example ---\n","example = test_data[0]\n","note_sequence = [t[0] for t in example]\n","true_chords = [t[2] for t in example]\n","\n","predicted_chords, confidences = predict_chords(model, note_sequence)\n","\n","print(\"True Chords:     \", true_chords)\n","print(\"Predicted Chords:\", predicted_chords)\n","print(\"Confidences: \", confidences)"]},{"cell_type":"code","execution_count":7,"id":"cb7d7956","metadata":{"execution":{"iopub.execute_input":"2025-04-15T09:25:02.073097Z","iopub.status.busy":"2025-04-15T09:25:02.072811Z","iopub.status.idle":"2025-04-15T09:25:03.480374Z","shell.execute_reply":"2025-04-15T09:25:03.479487Z"},"papermill":{"duration":1.432572,"end_time":"2025-04-15T09:25:03.481803","exception":false,"start_time":"2025-04-15T09:25:02.049231","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Cmaj, Cmaj, [0.13331948220729828]\n","Cmin, Cmin, [0.11815690249204636]\n","C#maj, C#maj, [0.24101538956165314]\n","C#min, C#min, [0.14509643614292145]\n","Dmaj, Dmaj, [0.17686399817466736]\n","Dmin, Dmin, [0.1446687877178192]\n","D#maj, D#maj, [0.16283133625984192]\n","D#min, D#min, [0.13204045593738556]\n","Emaj, Emaj, [0.1571585088968277]\n","Emin, Emin, [0.0978943333029747]\n","Fmaj, Fmaj, [0.16566616296768188]\n","Fmin, Fmin, [0.11311611533164978]\n","F#maj, F#maj, [0.17769040167331696]\n","F#min, F#min, [0.12576565146446228]\n","Gmaj, Gmaj, [0.09151533246040344]\n","Gmin, Gmin, [0.11302464455366135]\n","G#maj, G#maj, [0.07778660207986832]\n","G#min, G#min, [0.09653036296367645]\n","Amaj, Amaj, [0.07700403034687042]\n","Amin, Amin, [0.10019289702177048]\n","A#maj, A#maj, [0.1319868266582489]\n","A#min, A#min, [0.1178470328450203]\n","Bmaj, Bmaj, [0.07273509353399277]\n","Bmin, Bmin, [0.08100653439760208]\n"]},{"data":{"text/plain":["'for name, chord in chords.items():\\n    pred_chord = best_chord_match(chord, midi_chord_dict)\\n    print(f\"{name}, {chord_encodings[pred_chord]}\")'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["for name, chord in chords.items():\n","    pred_chord, conf = predict_chords(model, [chord])\n","    print(f\"{name}, {chord_encodings[pred_chord[0]]}, {conf}\")\n","\n","'''for name, chord in chords.items():\n","    pred_chord = best_chord_match(chord, midi_chord_dict)\n","    print(f\"{name}, {chord_encodings[pred_chord]}\")'''"]},{"cell_type":"code","execution_count":8,"id":"71562f90","metadata":{"execution":{"iopub.execute_input":"2025-04-15T09:25:03.530231Z","iopub.status.busy":"2025-04-15T09:25:03.529913Z","iopub.status.idle":"2025-04-15T09:25:03.534615Z","shell.execute_reply":"2025-04-15T09:25:03.533816Z"},"papermill":{"duration":0.029842,"end_time":"2025-04-15T09:25:03.535777","exception":false,"start_time":"2025-04-15T09:25:03.505935","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'all_true = []\\nall_pred = []\\n\\nfor example in test_data:\\n    note_sequence = [t[0] for t in example]\\n    true_chords = [t[2] for t in example]\\n    predicted_chords = predict_chords(model, note_sequence)\\n    \\n    all_true.extend(true_chords)\\n    all_pred.extend(predicted_chords)\\n\\n# Now use all_true and all_pred to make the confusion matrix\\ncm = confusion_matrix(all_true, all_pred, labels=range(NUM_CHORDS))\\n\\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[str(i) for i in range(NUM_CHORDS)])\\nfig, ax = plt.subplots(figsize=(10, 10))\\ndisp.plot(ax=ax, cmap=\\'Blues\\', xticks_rotation=45)\\nplt.title(\"Confusion Matrix - All Test Data\")\\nplt.xlabel(\"Predicted Chord\")\\nplt.ylabel(\"True Chord\")\\nplt.show()'"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["'''all_true = []\n","all_pred = []\n","\n","for example in test_data:\n","    note_sequence = [t[0] for t in example]\n","    true_chords = [t[2] for t in example]\n","    predicted_chords = predict_chords(model, note_sequence)\n","    \n","    all_true.extend(true_chords)\n","    all_pred.extend(predicted_chords)\n","\n","# Now use all_true and all_pred to make the confusion matrix\n","cm = confusion_matrix(all_true, all_pred, labels=range(NUM_CHORDS))\n","\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[str(i) for i in range(NUM_CHORDS)])\n","fig, ax = plt.subplots(figsize=(10, 10))\n","disp.plot(ax=ax, cmap='Blues', xticks_rotation=45)\n","plt.title(\"Confusion Matrix - All Test Data\")\n","plt.xlabel(\"Predicted Chord\")\n","plt.ylabel(\"True Chord\")\n","plt.show()'''"]},{"cell_type":"code","execution_count":9,"id":"696e7a96","metadata":{"execution":{"iopub.execute_input":"2025-04-15T09:25:03.583368Z","iopub.status.busy":"2025-04-15T09:25:03.583083Z","iopub.status.idle":"2025-04-15T09:25:03.629519Z","shell.execute_reply":"2025-04-15T09:25:03.628489Z"},"papermill":{"duration":0.071837,"end_time":"2025-04-15T09:25:03.63095","exception":false,"start_time":"2025-04-15T09:25:03.559113","status":"completed"},"tags":[]},"outputs":[],"source":["model.save('BestChordPredictor.keras')"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":6489604,"sourceId":10480441,"sourceType":"datasetVersion"},{"datasetId":6680282,"sourceId":10768712,"sourceType":"datasetVersion"},{"datasetId":6743943,"sourceId":10857170,"sourceType":"datasetVersion"}],"dockerImageVersionId":30840,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":351.958066,"end_time":"2025-04-15T09:25:06.761687","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-04-15T09:19:14.803621","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}